{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18SPQswUveYr"
   },
   "source": [
    "# Backtest VWAP performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQO01KjWvkbW"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRekX9Glu0RH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from hmmlearn.hmm import GaussianHMM, MultinomialHMM, GMMHMM\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fk8PRkMLH34d"
   },
   "outputs": [],
   "source": [
    "## GLOBAL VARS\n",
    "DATE_TIME = 'date_time'\n",
    "OPEN_PRICE = 'open'\n",
    "HIGH_PRICE = 'high'\n",
    "LOW_PRICE = 'low'\n",
    "CLOSE_PRICE = 'close'\n",
    "VOLUME = 'volume'\n",
    "FEATURES = ['high_low_spread', \"open_close_rets\", \"log_total_traded_vol\", \"daily_log_return\", \"short_term_vol\", \"long_term_vol\", \"money_flow_index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_QnKT3IvrQW"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdoHkrCjvNSm"
   },
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    filepath = os.path.join(DATAPATH, file)\n",
    "    df = pd.read_csv(\"file:///\" + filepath, parse_dates=[['<DTYYYYMMDD>', '<TIME>']])\n",
    "\n",
    "    return df\n",
    "\n",
    "def formatData(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df.drop(labels=[\"<TICKER>\", \"<PER>\", \"<OPENINT>\"], axis=\"columns\", inplace=True)\n",
    "    returned_df.columns = ['date_time', 'open', 'high', 'low', 'close', 'volume']\n",
    "    returned_df.set_index('date_time', drop=True, inplace=True)\n",
    "    returned_df = addDateAndTime(returned_df)\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "def prepareDataframe(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df['volume*price'] = returned_df['volume']*returned_df['close']\n",
    "    returned_df = returned_df.resample('5T').sum()\n",
    "    returned_df = returned_df.between_time('9:00', '17:25')\n",
    "    returned_df = returned_df[returned_df.index.weekday != 5]\n",
    "    returned_df = returned_df[returned_df.index.weekday != 6]\n",
    "    returned_df['vwap'] = returned_df['volume*price']/returned_df['volume']\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "def splitTrainTestData(df, size_in_years):\n",
    "    training_data = df[df.index[0]:df.index[0] + relativedelta(years=size_in_years, hours=-9, minutes = -5)]\n",
    "    test_data = df[df.index[0] + relativedelta(years=size_in_years, hours=-9):]\n",
    "\n",
    "    return training_data, test_data\n",
    "\n",
    "def split_train_test_data(df, size_in_years):\n",
    "    training_data = df[df.index[0]:df.index[-1] - relativedelta(years=size_in_years, hours=-9, minutes = -5)]\n",
    "    test_data = df[df.index[-1] - relativedelta(years=size_in_years, hours=-9):]\n",
    "\n",
    "    return training_data, test_data\n",
    "\n",
    "def getWeekdaysData(df):\n",
    "    df_mondays = df[df.index.weekday == 0]\n",
    "    df_tuesdays = df[df.index.weekday == 1]\n",
    "    df_wednesdays = df[df.index.weekday == 2]\n",
    "    df_thursdays = df[df.index.weekday == 3]\n",
    "    df_fridays = df[df.index.weekday == 4]\n",
    "\n",
    "    return df_mondays, df_tuesdays, df_wednesdays, df_thursdays, df_fridays\n",
    "\n",
    "def getWeekdaysDataDict(df):\n",
    "    weekdaysDataDict = {}\n",
    "    weekdaysDataDict[0] = df[df.index.weekday == 0]\n",
    "    weekdaysDataDict[1] = df[df.index.weekday == 1]\n",
    "    weekdaysDataDict[2] = df[df.index.weekday == 2]\n",
    "    weekdaysDataDict[3] = df[df.index.weekday == 3]\n",
    "    weekdaysDataDict[4] = df[df.index.weekday == 4]\n",
    "    weekdaysDataDict['else'] = df\n",
    "\n",
    "    return weekdaysDataDict\n",
    "\n",
    "def getStaticVolPredictorByWeekday(data, weekdaysDataDict):\n",
    "    staticVolPredictor = {}\n",
    "    staticVolPredictor[0] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(0))\n",
    "    staticVolPredictor[1] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(1))\n",
    "    staticVolPredictor[2] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(2))\n",
    "    staticVolPredictor[3] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(3))\n",
    "    staticVolPredictor[4] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(4))\n",
    "    staticVolPredictor['else'] = getNormalizedStaticVolPredictor(data)\n",
    "\n",
    "    return staticVolPredictor\n",
    "\n",
    "def getADVMedianByWeekday(data, weekdaysDataDict):\n",
    "    advMedian = {}\n",
    "    advMedian[0] = getADVMedian(weekdaysDataDict.get(0))\n",
    "    advMedian[1] = getADVMedian(weekdaysDataDict.get(1))\n",
    "    advMedian[2] = getADVMedian(weekdaysDataDict.get(2))\n",
    "    advMedian[3] = getADVMedian(weekdaysDataDict.get(3))\n",
    "    advMedian[4] = getADVMedian(weekdaysDataDict.get(4))\n",
    "    advMedian['else'] = getADVMedian(data)\n",
    "\n",
    "    return advMedian\n",
    "  \n",
    "def getDataByWeekDay(df, weekday):\n",
    "    df_weekday = df[df.index.weekday == weekday]\n",
    "\n",
    "    return df_weekday\n",
    "\n",
    "def addDateAndTime(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df['date'] = pd.to_datetime(returned_df.index.date)\n",
    "    returned_df['time'] = pd.to_datetime(returned_df.index, format = \"%m-%d-%Y %H:%M:%S\")\n",
    "    returned_df['time'] = returned_df['time'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "def getNormalizedStaticVolPredictor(df):\n",
    "    df = addDateAndTime(df)\n",
    "\n",
    "    static_volume_predictor = df.groupby(by='time')['volume'].median()\n",
    "    norm_static_volume_predictor = static_volume_predictor/sum(static_volume_predictor)\n",
    "    norm_static_volume_predictor.index = norm_static_volume_predictor.index.map(lambda x: datetime.strptime(x, '%X').time())\n",
    "\n",
    "    return norm_static_volume_predictor\n",
    "\n",
    "def getReversedCumVol(multi_data, data):\n",
    "    reversed_cumvol = []\n",
    "    for day in multi_data.index.get_level_values('Date').unique():\n",
    "        reversed_cumvol.append(multi_data.xs(day, level='Date')['volume'].cumsum().values[::-1])\n",
    "\n",
    "    reversed_cumvol = pd.Series(data = np.array(reversed_cumvol).flatten(), index = data.index)\n",
    "\n",
    "    return reversed_cumvol\n",
    "\n",
    "def getADVMedian(df):\n",
    "    return df['volume'].groupby(df.index.date).sum().median()\n",
    "\n",
    "def getADVMean(df):\n",
    "    return df['volume'].groupby(df.index.date).sum().median()\n",
    "\n",
    "def getDailyVWAP(df):\n",
    "    return df['volume*price'].groupby(df.index.date).sum()/df['volume'].groupby(df.index.date).sum()\n",
    "  \n",
    "def getVolPredictorNextBin(test_data, staticVolPredictor, advMedian):\n",
    "    volume_predictor_next_interval = test_data.groupby(level=0)['volume'].shift(1)\n",
    "    volume_predictor_next_interval.fillna(int (advMedian.get('else')*staticVolPredictor.get('else').iloc[0]), inplace=True)\n",
    "\n",
    "    return volume_predictor_next_interval\n",
    "  \n",
    "def vwap_static_execution_algo(data, staticVolPredictor, amount_shares, order_side, start_time, end_time, day):\n",
    "    if day.weekday() == 0:\n",
    "        volPredictor = staticVolPredictor.get(0)[start_time:end_time]\n",
    "    elif day.weekday() == 1:\n",
    "        volPredictor = staticVolPredictor.get(1)[start_time:end_time]\n",
    "    elif day.weekday() == 2:\n",
    "        volPredictor = staticVolPredictor.get(2)[start_time:end_time]\n",
    "    elif day.weekday() == 3:\n",
    "        volPredictor = staticVolPredictor.get(3)[start_time:end_time]\n",
    "    elif day.weekday() == 4:\n",
    "        volPredictor = staticVolPredictor.get(4)[start_time:end_time]\n",
    "    else:\n",
    "        volPredictor = staticVolPredictor.get('else')[start_time:end_time]\n",
    "\n",
    "    shares_per_interval = volPredictor*amount_shares\n",
    "    vwap_this_exec_this_day = sum(shares_per_interval*data['vwap'])/sum(shares_per_interval)\n",
    "\n",
    "    return vwap_this_exec_this_day\n",
    "\n",
    "def vwap_dynamic_execution_algo(data, reversed_cumvol, staticVolPredictor, volume_predictor_next_interval, amount_shares, order_side, start_time, end_time, day):\n",
    "    shares_per_interval = []\n",
    "    if day.weekday() == 0:\n",
    "        shares_per_interval.append(staticVolPredictor.get(0).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 0].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 0].index.time).median()\n",
    "    elif day.weekday() == 1:\n",
    "        shares_per_interval.append(staticVolPredictor.get(1).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 1].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 1].index.time).median()\n",
    "    elif day.weekday() == 2:\n",
    "        shares_per_interval.append(staticVolPredictor.get(2).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 2].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 2].index.time).median()\n",
    "    elif day.weekday() == 3:\n",
    "        shares_per_interval.append(staticVolPredictor.get(3).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 3].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 3].index.time).median()\n",
    "    elif day.weekday() == 4:\n",
    "        shares_per_interval.append(staticVolPredictor.get(4).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 4].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 4].index.time).median()\n",
    "    else:\n",
    "        shares_per_interval.append(staticVolPredictor.get('else').iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol.groupby(reversed_cumvol.index.time).median()\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        num = data['volume'].iloc[:i].sum()+volume_predictor_next_interval.xs(day, level='Date').iloc[i]\n",
    "        denom = data['volume'].iloc[:i].sum()+volPredictor[i]\n",
    "        op = amount_shares*(num/denom)\n",
    "        shares_next_interval = op - sum(shares_per_interval)\n",
    "        #     shares_next_interval = (amount_shares*((data['volume'].iloc[0:i].sum()+volume_predictor_next_interval.xs(day, level='Date').iloc[i])/(data['volume'].iloc[0:i].sum()+volPredictor[i])))-sum(shares_per_interval)\n",
    "        shares_per_interval.append(shares_next_interval)\n",
    "\n",
    "    vwap_this_exec_this_day = sum(shares_per_interval*data['vwap'])/sum(shares_per_interval)\n",
    "\n",
    "    return vwap_this_exec_this_day\n",
    "\n",
    "def dataToMultiIndex(data):\n",
    "    multi_data = data.copy()\n",
    "    multi_data.index = pd.MultiIndex.from_arrays([multi_data.index.date, multi_data.index.time], names=['Date','Time'])\n",
    "\n",
    "    return multi_data\n",
    "\n",
    "def backtestAlgoStatic(training_data, test_data, advMedian, staticVolPredictor):\n",
    "    new_test_data = test_data.copy()\n",
    "    new_test_data.index = pd.MultiIndex.from_arrays([new_test_data.index.date, new_test_data.index.time], names=['Date','Time'])\n",
    "\n",
    "    backtest_sell_vwap = []\n",
    "    backtest_buy_vwap = []\n",
    "    \n",
    "    for day in new_test_data.index.get_level_values('Date').unique():\n",
    "        data = new_test_data.xs(day, level='Date')\n",
    "\n",
    "        if day.weekday() == 0:\n",
    "            amount_shares = advMedian.get(0)*0.1\n",
    "        elif day.weekday() == 1:\n",
    "            amount_shares = advMedian.get(1)*0.1\n",
    "        elif day.weekday() == 2:\n",
    "            amount_shares = advMedian.get(2)*0.1\n",
    "        elif day.weekday() == 3:\n",
    "            amount_shares = advMedian.get(3)*0.1\n",
    "        elif day.weekday() == 4:\n",
    "            amount_shares = advMedian.get(4)*0.1\n",
    "        else:\n",
    "            amount_shares = advMedian.get('else')*0.1\n",
    "\n",
    "        backtest_sell_vwap.append(vwap_static_execution_algo(data, staticVolPredictor, amount_shares, 'sell' ,data.index[0], data.index[-1], day))\n",
    "        backtest_buy_vwap.append(vwap_static_execution_algo(data, staticVolPredictor, amount_shares, 'buy', data.index[0], data.index[-1], day))\n",
    "\n",
    "    return backtest_buy_vwap, backtest_sell_vwap\n",
    "\n",
    "def backtestAlgoDynamic(training_data, test_data, advMedian, staticVolPredictor):\n",
    "    new_training_data = dataToMultiIndex(training_data)\n",
    "    new_test_data = dataToMultiIndex(test_data)\n",
    "    reversedCumVol = getReversedCumVol(new_training_data, training_data)\n",
    "    volPredictorNextBin = getVolPredictorNextBin(new_test_data, staticVolPredictor, advMedian)\n",
    "\n",
    "\n",
    "    backtest_sell_vwap_dynamic = []\n",
    "    backtest_buy_vwap_dynamic = []\n",
    "    for day in new_test_data.index.get_level_values('Date').unique():\n",
    "        data = new_test_data.xs(day, level='Date')\n",
    "        if day.weekday() == 0:\n",
    "            amount_shares = advMedian.get(0)*0.1\n",
    "        elif day.weekday() == 1:\n",
    "            amount_shares = advMedian.get(1)*0.1\n",
    "        elif day.weekday() == 2:\n",
    "            amount_shares = advMedian.get(2)*0.1\n",
    "        elif day.weekday() == 3:\n",
    "            amount_shares = advMedian.get(3)*0.1\n",
    "        elif day.weekday() == 4:\n",
    "            amount_shares = advMedian.get(4)*0.1\n",
    "        else:\n",
    "            amount_shares = advMedian.get('else')*0.1\n",
    "        backtest_sell_vwap_dynamic.append(vwap_dynamic_execution_algo(data, reversedCumVol, staticVolPredictor, volPredictorNextBin, amount_shares, 'sell', data.index[0], data.index[-1], day))\n",
    "        backtest_buy_vwap_dynamic.append(vwap_dynamic_execution_algo(data, reversedCumVol, staticVolPredictor, volPredictorNextBin, amount_shares, 'buy', data.index[0], data.index[-1], day))\n",
    "\n",
    "    return backtest_buy_vwap_dynamic, backtest_sell_vwap_dynamic\n",
    "  \n",
    "def getAlgoPerformance(training_data, test_data, dynamic_flag):\n",
    "    daily_vwap = getDailyVWAP(test_data)\n",
    "    weekdaysDataDict = getWeekdaysDataDict(training_data)\n",
    "    staticVolPredictor = getStaticVolPredictorByWeekday(training_data, weekdaysDataDict)\n",
    "    advMedian = getADVMedianByWeekday(training_data, weekdaysDataDict)\n",
    "\n",
    "    if dynamic_flag:\n",
    "        backtest_buy_vwap, backtest_sell_vwap = backtestAlgoDynamic(training_data, test_data, advMedian, staticVolPredictor)\n",
    "    else:\n",
    "        backtest_buy_vwap, backtest_sell_vwap = backtestAlgoStatic(training_data, test_data, advMedian, staticVolPredictor)\n",
    "\n",
    "    static_vwap_comparison = pd.DataFrame(data=daily_vwap.values.tolist(), index=daily_vwap.index, columns=['market_vwap'])\n",
    "    static_vwap_comparison['backtest_buy_vwap'] = backtest_buy_vwap\n",
    "    static_vwap_comparison['backtest_sell_vwap'] = backtest_sell_vwap\n",
    "\n",
    "    static_vwap_comparison['diff_vwap_bps_buy'] = 1000*(static_vwap_comparison['backtest_buy_vwap']-static_vwap_comparison['market_vwap'])/static_vwap_comparison['market_vwap']\n",
    "    static_vwap_comparison['diff_vwap_bps_sell'] = -1000*(static_vwap_comparison['backtest_sell_vwap']-static_vwap_comparison['market_vwap'])/static_vwap_comparison['market_vwap']\n",
    "\n",
    "    mean_bps_diff_buys = static_vwap_comparison['diff_vwap_bps_buy'].mean()\n",
    "    sd_bps_diff_buys = static_vwap_comparison['diff_vwap_bps_buy'].std()\n",
    "    mean_bps_diff_sells = static_vwap_comparison['diff_vwap_bps_sell'].mean()\n",
    "    sd_bps_diff_sells = static_vwap_comparison['diff_vwap_bps_sell'].std()\n",
    "\n",
    "    percentiles_diff_vwap_sells = {'1': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.01),\n",
    "                               '5': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.05),\n",
    "                               '95': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.95),\n",
    "                               '99': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.99)}\n",
    "    percentiles_diff_vwap_buys = {'1': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.01),\n",
    "                               '5': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.05),\n",
    "                               '95': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.95),\n",
    "                               '99': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.99)}\n",
    "\n",
    "    return mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells\n",
    "\n",
    "def printAlgoPerformance(file, ticker):\n",
    "    filepath = os.path.join(DATAPATH, file)\n",
    "\n",
    "    df = pd.read_csv(\"file:///\" + filepath, parse_dates=[['<DTYYYYMMDD>', '<TIME>']])\n",
    "    formatted_df = formatData(df)\n",
    "    formatted_df = formatted_df[formatted_df.index.year >= 2009]\n",
    "    last_year = formatted_df.index.year.unique()[-2]\n",
    "    algo_df = prepareDataframe(formatted_df)\n",
    "    train = algo_df[algo_df.index.year < last_year]\n",
    "    test = algo_df[algo_df.index.year >= last_year]\n",
    "\n",
    "    print(\"Backtesting performance with static predictor...\\n\")\n",
    "    mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformance(train, test, dynamic_flag=False)\n",
    "    print(\"The performance of the algorithm using static predictor on \" + ticker + \" is\")\n",
    "    print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    print(\"Backtesting performance with dynamic predictor...\\n\")\n",
    "    mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformance(train, test, dynamic_flag=True)\n",
    "    print(\"The performance of the algorithm using dynamic predictor on \" + ticker + \" is\")\n",
    "    print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Fitting Gaussian Mixture Model...\")\n",
    "\n",
    "    high_low = get_log(np.abs(get_high_low_spread(formatted_df)))\n",
    "    open_close_log_rets = get_log_open_close_returns(formatted_df)\n",
    "    total_traded_vol = get_log(get_total_traded_vol(formatted_df))\n",
    "\n",
    "    features_df = pd.concat([high_low, open_close_log_rets, total_traded_vol], axis=1).dropna()\n",
    "    features_df.columns = ['hl_spread', \"log_return\", \"traded_vol\"]\n",
    "    features_df = features_df.replace([np.inf, -np.inf], np.nan)\n",
    "    features_df = features_df.dropna()\n",
    "    features_df = features_df[features_df['log_return'] != 0.0]\n",
    "    features_df = features_df[features_df['hl_spread'] != 0.0]\n",
    "    features_df = features_df[[\"traded_vol\"]]\n",
    "    # features_df = features_df[['hl_spread', \"log_return\", \"traded_vol\"]]\n",
    "\n",
    "    features_df = features_df.shift(1).dropna()\n",
    "\n",
    "    features_train = features_df[features_df.index.year < last_year]\n",
    "    features_test = features_df[features_df.index.year >= last_year]\n",
    "\n",
    "    X = features_train.values\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    # pca = PCA(n_components=.95)\n",
    "    # pca.fit(X_scaled)\n",
    "    # X_pca = pca.transform(X_scaled)\n",
    "\n",
    "    gmm = GaussianMixture(n_components=3, covariance_type='full', max_iter=1000, n_init=100)\n",
    "    model = gmm.fit(X_scaled)\n",
    "\n",
    "    X = features_df.values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    # X_pca = pca.transform(X_scaled)\n",
    "\n",
    "    prediction_gmm = model.predict(X_scaled)\n",
    "    # prediction_gmm = hmm_model.predict(X_pca)\n",
    "\n",
    "    print(\"Model fitted\\n\\n\")\n",
    "    features_df['regime'] = prediction_gmm\n",
    "    regime = features_df[['regime']]\n",
    "    regime = regime.resample(\"5T\").asfreq().fillna(method=\"ffill\")\n",
    "\n",
    "    new_df = pd.merge(algo_df, regime, left_index=True, right_index=True)\n",
    "    new_df = new_df.astype({\"regime\":\"int32\"})\n",
    "\n",
    "    train = new_df[new_df.index.year < last_year]\n",
    "    test = new_df[new_df.index.year >= last_year]\n",
    "\n",
    "    print(\"Backtesting performance of static predictor using segmented data...\\n\")\n",
    "    mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=False, regimes=new_df['regime'].unique())\n",
    "    print(\"The performance of the algorithm using static predictor with segmented data on \" + ticker + \" is\")\n",
    "    print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    print(\"Backtesting performance of dynamic predictor using segmented data...\\n\")\n",
    "    mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=True, regimes=new_df['regime'].unique())\n",
    "    print(\"The performance of the algorithm using static predictor with segmented data on \" + ticker + \" is\")\n",
    "    print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "\n",
    "def vwap_static_execution_algo(data, staticVolPredictor, amount_shares, order_side, start_time, end_time, day):\n",
    "    if day.weekday() == 0:\n",
    "        volPredictor = staticVolPredictor.get(0)[start_time:end_time]\n",
    "    elif day.weekday() == 1:\n",
    "        volPredictor = staticVolPredictor.get(1)[start_time:end_time]\n",
    "    elif day.weekday() == 2:\n",
    "        volPredictor = staticVolPredictor.get(2)[start_time:end_time]\n",
    "    elif day.weekday() == 3:\n",
    "        volPredictor = staticVolPredictor.get(3)[start_time:end_time]\n",
    "    elif day.weekday() == 4:\n",
    "        volPredictor = staticVolPredictor.get(4)[start_time:end_time]\n",
    "    else:\n",
    "        volPredictor = staticVolPredictor.get('else')[start_time:end_time]\n",
    "\n",
    "    shares_per_interval = volPredictor*amount_shares\n",
    "    vwap_this_exec_this_day = sum(shares_per_interval*data['vwap'])/sum(shares_per_interval)\n",
    "\n",
    "    return vwap_this_exec_this_day\n",
    "\n",
    "def vwap_dynamic_execution_algo(data, reversed_cumvol, staticVolPredictor, volume_predictor_next_interval, amount_shares, order_side, start_time, end_time, day):\n",
    "    shares_per_interval = []\n",
    "    if day.weekday() == 0:\n",
    "        shares_per_interval.append(staticVolPredictor.get(0).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 0].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 0].index.time).median()\n",
    "    elif day.weekday() == 1:\n",
    "        shares_per_interval.append(staticVolPredictor.get(1).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 1].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 1].index.time).median()\n",
    "    elif day.weekday() == 2:\n",
    "        shares_per_interval.append(staticVolPredictor.get(2).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 2].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 2].index.time).median()\n",
    "    elif day.weekday() == 3:\n",
    "        shares_per_interval.append(staticVolPredictor.get(3).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 3].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 3].index.time).median()\n",
    "    elif day.weekday() == 4:\n",
    "        shares_per_interval.append(staticVolPredictor.get(4).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 4].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 4].index.time).median()\n",
    "    else:\n",
    "        shares_per_interval.append(staticVolPredictor.get('else').iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol.groupby(reversed_cumvol.index.time).median()\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        num = data['volume'].iloc[:i].sum()+volume_predictor_next_interval.xs(day, level='Date').iloc[i]\n",
    "        denom = data['volume'].iloc[:i].sum()+volPredictor[i]\n",
    "        op = amount_shares*(num/denom)\n",
    "        shares_next_interval = op - sum(shares_per_interval)\n",
    "        shares_per_interval.append(shares_next_interval)\n",
    "\n",
    "    vwap_this_exec_this_day = sum(shares_per_interval*data['vwap'])/sum(shares_per_interval)\n",
    "\n",
    "    return vwap_this_exec_this_day\n",
    "\n",
    "def backtestAlgoStaticByRegime(training_data, test_data, advMedian, staticVolPredictor):\n",
    "    new_test_data = test_data.copy()\n",
    "    new_test_data.index = pd.MultiIndex.from_arrays([new_test_data.index.date,\n",
    "                                                   new_test_data.index.time],\n",
    "                                                   names=['Date','Time'])\n",
    "\n",
    "    backtest_sell_vwap = []\n",
    "    backtest_buy_vwap = []\n",
    "    \n",
    "    for day in new_test_data.index.get_level_values('Date').unique():\n",
    "        data = new_test_data.xs(day, level='Date')\n",
    "        regime = data['regime'].iloc[0]\n",
    "        if day.weekday() == 0:\n",
    "            amount_shares = advMedian.get(regime).get(0)*0.1\n",
    "        elif day.weekday() == 1:\n",
    "            amount_shares = advMedian.get(regime).get(1)*0.1\n",
    "        elif day.weekday() == 2:\n",
    "            amount_shares = advMedian.get(regime).get(2)*0.1\n",
    "        elif day.weekday() == 3:\n",
    "            amount_shares = advMedian.get(regime).get(3)*0.1\n",
    "        elif day.weekday() == 4:\n",
    "            amount_shares = advMedian.get(regime).get(4)*0.1\n",
    "        else:\n",
    "            amount_shares = advMedian.get(regime).get('else')*0.1\n",
    "        \n",
    "    backtest_sell_vwap.append(vwap_static_execution_algo(data,\n",
    "                                                         staticVolPredictor.get(regime),\n",
    "                                                         amount_shares,\n",
    "                                                         'sell',\n",
    "                                                         data.index[0],\n",
    "                                                         data.index[-1],\n",
    "                                                         day))\n",
    "    backtest_buy_vwap.append(vwap_static_execution_algo(data,\n",
    "                                                        staticVolPredictor.get(regime),\n",
    "                                                        amount_shares,\n",
    "                                                        'buy',\n",
    "                                                        data.index[0],\n",
    "                                                        data.index[-1],\n",
    "                                                        day))\n",
    "\n",
    "    return backtest_buy_vwap, backtest_sell_vwap\n",
    "\n",
    "def backtestAlgoDynamicByRegime(training_data, test_data, advMedian, staticVolPredictor, regimes):\n",
    "    new_training_data = dataToMultiIndex(training_data)\n",
    "    new_test_data = dataToMultiIndex(test_data)\n",
    "    regime_reversedCumVol = {}\n",
    "    regime_volPredictorNextBin = {}\n",
    "    for regime in regimes:\n",
    "        regime_reversedCumVol[regime] = getReversedCumVol(new_training_data[new_training_data['regime']==regime], \n",
    "                                                          training_data[training_data['regime']==regime])\n",
    "        regime_volPredictorNextBin[regime] = getVolPredictorNextBin(new_test_data[new_test_data['regime']==regime], \n",
    "                                                                    staticVolPredictor.get(regime),\n",
    "                                                                    advMedian.get(regime))\n",
    "\n",
    "    backtest_sell_vwap_dynamic = []\n",
    "    backtest_buy_vwap_dynamic = []\n",
    "    for day in new_test_data.index.get_level_values('Date').unique():\n",
    "        data = new_test_data.xs(day, level='Date')\n",
    "        regime = data['regime'].iloc[0]\n",
    "        if day.weekday() == 0:\n",
    "            amount_shares = advMedian.get(regime).get(0)*0.1\n",
    "        elif day.weekday() == 1:\n",
    "            amount_shares = advMedian.get(regime).get(1)*0.1\n",
    "        elif day.weekday() == 2:\n",
    "            amount_shares = advMedian.get(regime).get(2)*0.1\n",
    "        elif day.weekday() == 3:\n",
    "            amount_shares = advMedian.get(regime).get(3)*0.1\n",
    "        elif day.weekday() == 4:\n",
    "            amount_shares = advMedian.get(regime).get(4)*0.1\n",
    "        else:\n",
    "            amount_shares = advMedian.get(regime).get('else')*0.1\n",
    "            \n",
    "        backtest_sell_vwap_dynamic.append(vwap_dynamic_execution_algo(data, \n",
    "                                                                      regime_reversedCumVol.get(regime),\n",
    "                                                                      staticVolPredictor.get(regime),\n",
    "                                                                      regime_volPredictorNextBin.get(regime),\n",
    "                                                                      amount_shares, \n",
    "                                                                      'sell',\n",
    "                                                                      data.index[0],\n",
    "                                                                      data.index[-1], day))\n",
    "        backtest_buy_vwap_dynamic.append(vwap_dynamic_execution_algo(data,\n",
    "                                                                     regime_reversedCumVol.get(regime),\n",
    "                                                                     staticVolPredictor.get(regime),\n",
    "                                                                     regime_volPredictorNextBin.get(regime),\n",
    "                                                                     amount_shares,\n",
    "                                                                     'buy',\n",
    "                                                                     data.index[0],\n",
    "                                                                     data.index[-1],\n",
    "                                                                     day))\n",
    "\n",
    "    return backtest_buy_vwap_dynamic, backtest_sell_vwap_dynamic\n",
    "\n",
    "def getAlgoPerformanceByRegime(training_data, test_data, dynamic_flag, regimes):\n",
    "    regime_daily_vwap = {}\n",
    "    regime_weekdaysDataDict = {}\n",
    "    regime_staticVolPredictor = {}\n",
    "    regime_advMedian = {}\n",
    "    daily_vwap = getDailyVWAP(test_data)\n",
    "    for regime in regimes:\n",
    "        regime_daily_vwap[regime] = getDailyVWAP(test_data[test_data['regime'] == regime])\n",
    "        regime_weekdaysDataDict[regime] = getWeekdaysDataDict(training_data[training_data['regime'] == regime])\n",
    "        regime_staticVolPredictor[regime] = getStaticVolPredictorByWeekday(training_data[training_data['regime'] == regime], regime_weekdaysDataDict[regime])\n",
    "        regime_advMedian[regime] = getADVMedianByWeekday(training_data[training_data['regime'] == regime], regime_weekdaysDataDict[regime])\n",
    "\n",
    "    if dynamic_flag:\n",
    "        backtest_buy_vwap, backtest_sell_vwap = backtestAlgoDynamicByRegime(training_data, test_data, regime_advMedian, regime_staticVolPredictor, regimes)\n",
    "    else:\n",
    "        backtest_buy_vwap, backtest_sell_vwap = backtestAlgoStaticByRegime(training_data, test_data, regime_advMedian, regime_staticVolPredictor)\n",
    "\n",
    "    static_vwap_comparison = pd.DataFrame(data=daily_vwap.values.tolist(), index=daily_vwap.index, columns=['market_vwap'])\n",
    "    static_vwap_comparison['backtest_buy_vwap'] = backtest_buy_vwap\n",
    "    static_vwap_comparison['backtest_sell_vwap'] = backtest_sell_vwap\n",
    "\n",
    "    static_vwap_comparison['diff_vwap_bps_buy'] = 1000*(static_vwap_comparison['backtest_buy_vwap']-static_vwap_comparison['market_vwap'])/static_vwap_comparison['market_vwap']\n",
    "    static_vwap_comparison['diff_vwap_bps_sell'] = -1000*(static_vwap_comparison['backtest_sell_vwap']-static_vwap_comparison['market_vwap'])/static_vwap_comparison['market_vwap']\n",
    "\n",
    "    mean_bps_diff_buys = static_vwap_comparison['diff_vwap_bps_buy'].mean()\n",
    "    sd_bps_diff_buys = static_vwap_comparison['diff_vwap_bps_buy'].std()\n",
    "    mean_bps_diff_sells = static_vwap_comparison['diff_vwap_bps_sell'].mean()\n",
    "    sd_bps_diff_sells = static_vwap_comparison['diff_vwap_bps_sell'].std()\n",
    "\n",
    "    percentiles_diff_vwap_sells = {'1': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.01),\n",
    "                               '5': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.05),\n",
    "                               '95': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.95),\n",
    "                               '99': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.99)}\n",
    "    percentiles_diff_vwap_buys = {'1': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.01),\n",
    "                               '5': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.05),\n",
    "                               '95': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.95),\n",
    "                               '99': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.99)}\n",
    "\n",
    "    return mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells\n",
    "\n",
    "def get_total_traded_vol(df):\n",
    "    total_traded_vol = df.resample('B').sum()[['volume']]\n",
    "    total_traded_vol.drop(labels=total_traded_vol.index.get_values()[0], axis='index', inplace=True)\n",
    "\n",
    "    return total_traded_vol\n",
    "\n",
    "def get_log_open_close_returns_(df):\n",
    "    # open_close_returns = df[(df['time'] == '09:01:00') | (df['time'] == '17:35:00')]\n",
    "    open_close_returns = df[(df['time'] == '09:00:00') | (df['time'] == '17:35:00')]\n",
    "    open_close_returns['return'] = (open_close_returns['open']/open_close_returns['close'].shift(-1))\n",
    "    open_close_returns['log_return'] = np.log(open_close_returns['return'])\n",
    "    # open_close_returns = open_close_returns[open_close_returns['time'] == '09:01:00']\n",
    "    open_close_returns = open_close_returns[open_close_returns['time'] == '09:00:00']\n",
    "    open_close_returns = open_close_returns[['log_return']].resample('B').sum()\n",
    "\n",
    "    return open_close_returns\n",
    "\n",
    "def get_log_open_close_returns(df):\n",
    "    open_price = df[OPEN_PRICE].resample('B').first()\n",
    "    close_price = df[CLOSE_PRICE].resample('B').last()\n",
    "    open_close_returns = np.log(open_price/close_price.shift(-1)).dropna()\n",
    "\n",
    "    return open_close_returns\n",
    "\n",
    "def get_log_returns(df):\n",
    "    close = df[CLOSE_PRICE].resample('B').last()\n",
    "    log_daily_returns = np.log(close/close.shift(-1))\n",
    "\n",
    "    return log_daily_returns\n",
    "\n",
    "def get_high_low_spread(df):\n",
    "    daily_high = df.resample(\"B\").max()[['high']]\n",
    "    daily_low = df.resample(\"B\").min()[['low']]\n",
    "    high_low_spread = (daily_high['high']-daily_low['low'])\n",
    "\n",
    "    return high_low_spread\n",
    "\n",
    "def get_log(df):\n",
    "    return np.log(df)\n",
    "\n",
    "def getFeaturesDf(df):\n",
    "    high_low = get_log(np.abs(get_high_low_spread(df)))\n",
    "    open_close_log_rets = get_log_open_close_returns(df)\n",
    "    total_traded_vol = get_log(get_total_traded_vol(df))\n",
    "\n",
    "    features_df = pd.concat([high_low, open_close_log_rets, total_traded_vol], axis=1).dropna()\n",
    "    features_df.columns = ['hl_spread', \"log_return\", \"traded_vol\"]\n",
    "    features_df = features_df.replace([np.inf, -np.inf], np.nan)\n",
    "    features_df = features_df.dropna()\n",
    "    features_df = features_df[features_df['log_return'] != 0.0]\n",
    "    features_df = features_df[features_df['hl_spread'] != 0.0]\n",
    "\n",
    "    return features_df\n",
    "\n",
    "def processDataToFit(features_df):\n",
    "    X = features_df.values\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    pca = PCA(n_components=.95)\n",
    "    pca.fit(X)\n",
    "    X_pca = pca.transform(X)\n",
    "\n",
    "    return X_pca\n",
    "\n",
    "def fit_model(model, full_data, train_data, list_of_features):\n",
    "    X = train_data.values\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    if len(list_of_features) > 2:\n",
    "        pca = PCA(n_components=.95)\n",
    "        pca.fit(X_scaled)\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        fitted_model = model.fit(X_pca)\n",
    "        X_full = full_data.values\n",
    "        X_full_scaled = scaler.transform(X_full)\n",
    "        X_full_pca = pca.transform(X_full_scaled)\n",
    "        prediction = fitted_model.predict(X_full_pca)\n",
    "    else:\n",
    "        fitted_model = model.fit(X_scaled)\n",
    "        X_full = full_data.values\n",
    "        X_full_scaled = scaler.transform(X_full)\n",
    "        prediction = fitted_model.predict(X_full_scaled)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def get_money_flow_index(df):\n",
    "    close = df[CLOSE_PRICE].resample('B').last()\n",
    "    high = df[HIGH_PRICE].resample('B').max()\n",
    "    low = df[LOW_PRICE].resample('B').min()\n",
    "    typical_price = (close+high+low)/3\n",
    "    volume = df[VOLUME].resample('B').sum()\n",
    "    money_flow_index = typical_price/volume\n",
    "\n",
    "    return money_flow_index\n",
    "\n",
    "def fit_model_by_weekday(model, full_data, train_data, list_of_features):\n",
    "    regime = []\n",
    "    for weekday in [0,1,2,3,4]:\n",
    "        model_weekday = model\n",
    "        X = train_data[train_data.index.weekday == weekday].values\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "\n",
    "        if len(list_of_features) > 2:\n",
    "            pca = PCA(n_components=.95)\n",
    "            pca.fit(X_scaled)\n",
    "            X_pca = pca.transform(X_scaled)\n",
    "            fitted_model = model_weekday.fit(X_pca)\n",
    "            X_full = full_data[full_data.index.weekday == weekday].values\n",
    "            X_full_scaled = scaler.transform(X_full)\n",
    "            X_full_pca = pca.transform(X_full_scaled)\n",
    "            prediction = fitted_model.predict(X_full_pca)\n",
    "        else:\n",
    "            fitted_model = model_weekday.fit(X_scaled)\n",
    "            X_full = full_data.values\n",
    "            X_full_scaled = scaler.transform(X_full)\n",
    "            prediction = fitted_model.predict(X_full_scaled)\n",
    "\n",
    "        regime_serie = pd.Series(data = prediction, index = full_data[full_data.index.weekday == weekday].index).rename(\"regime\")\n",
    "        regime_serie = regime_serie.resample(\"5T\").asfreq().fillna(method=\"ffill\")\n",
    "        regime.append(regime_serie)\n",
    "\n",
    "    regime_df = regime[0]\n",
    "    for ii in range(1,5):\n",
    "        pd.concat(regime_df, regime[ii])\n",
    "\n",
    "    return regime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8086,
     "status": "ok",
     "timestamp": 1583857142232,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "yAbDsdKDvH-X",
    "outputId": "2f07e6f7-4f8d-4a36-d358-872eabefe08b"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "DATAPATH = os.getcwd()[:-4]+\"Data\\\\\"\n",
    "filepath_anon = os.path.join(DATAPATH, \"volume_price_2014_18.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgclcpbuGRBB"
   },
   "outputs": [],
   "source": [
    "def printFullAlgoPerformance(file, ticker, features_to_use, normal_vwap=True, machine_learning=True, from_year=2008, calibrate_by_weekday=False, static_predictor=True, dynamic_predictor=True):\n",
    "    filepath = os.path.join(DATAPATH, file)\n",
    "    df = pd.read_csv(\"file:///\" + filepath, parse_dates=[['<DTYYYYMMDD>', '<TIME>']])\n",
    "    formatted_df = formatData(df)\n",
    "\n",
    "    first_year = formatted_df.index[0].year\n",
    "    if from_year >= first_year:\n",
    "        formatted_df = formatted_df[formatted_df.index.year >= from_year]\n",
    "\n",
    "    print(\"Backtesting {}. Using data from {}\\n\".format(ticker, formatted_df.index[0].year))\n",
    "\n",
    "    enough_data = True\n",
    "\n",
    "    last_year = formatted_df.index.year.unique()[-1]\n",
    "    algo_df = prepareDataframe(formatted_df)\n",
    "#     train = algo_df[algo_df.index.year < last_year]\n",
    "#     test = algo_df[algo_df.index.year >= last_year]\n",
    "\n",
    "#     ## If test data has less than 150 business days, use previous year\n",
    "#     if len(test) < 150*102:\n",
    "#         train = algo_df[algo_df.index.year < (last_year - 1)]\n",
    "#         test = algo_df[algo_df.index.year >= (last_year - 1)]\n",
    "#         enough_data = False\n",
    "\n",
    "    train, test = split_train_test_data(algo_df, 2)\n",
    "\n",
    "\n",
    "    if normal_vwap:\n",
    "\n",
    "        if static_predictor:\n",
    "            print(\"Backtesting performance with static predictor...\\n\")\n",
    "            mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformance(train, test, dynamic_flag=False)\n",
    "            print(\"The performance of the algorithm using static predictor on \" + ticker + \" is\")\n",
    "            print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "\n",
    "            print(\"-\"*80)\n",
    "\n",
    "        if dynamic_predictor:\n",
    "            print(\"Backtesting performance with dynamic predictor...\\n\")\n",
    "            mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformance(train, test, dynamic_flag=True)\n",
    "            print(\"The performance of the algorithm using dynamic predictor on \" + ticker + \" is\")\n",
    "            print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "\n",
    "            print(\"-\"*80)\n",
    "\n",
    "    if machine_learning:\n",
    "        high_low = get_log(np.abs(get_high_low_spread(formatted_df))).rename(\"high_low_spread\")\n",
    "        open_close_log_rets = get_log_open_close_returns(formatted_df).rename(\"open_close_rets\")\n",
    "        total_traded_vol = np.exp(get_log(get_total_traded_vol(formatted_df))[VOLUME]).rename(\"log_total_traded_vol\")\n",
    "        daily_log_rets = get_log_returns(formatted_df).rename(\"daily_log_return\").dropna()\n",
    "        short_term_vol = daily_log_rets.rolling(21).std().dropna().rename(\"short_term_vol\")\n",
    "        #     short_term_vol = daily_log_rets.rolling(252).std().dropna().apply(lambda x: x/np.sqrt(21)).rename(\"short_term_vol\")\n",
    "        long_term_vol = daily_log_rets.dropna().rolling(252).std(ddof=0).dropna().rename(\"long_term_vol\")\n",
    "        implied_daily_vol = (daily_log_rets.dropna().rolling(252).std(ddof=0).dropna()/np.sqrt(252)).rename(\"implied_daily_vol\")\n",
    "        mfi = get_log(get_money_flow_index(formatted_df).rename(\"money_flow_index\"))\n",
    "\n",
    "        features_df = pd.concat([high_low, open_close_log_rets, total_traded_vol, daily_log_rets, short_term_vol, long_term_vol, mfi, implied_daily_vol], axis=1).dropna()\n",
    "        features_df = features_df.replace([np.inf, -np.inf], np.nan)\n",
    "        features_df = features_df.dropna()\n",
    "        # features_df = features_df[features_df['log_return'] != 0.0]\n",
    "        # features_df = features_df[features_df['hl_spread'] != 0.0]\n",
    "        features_df = features_df[features_to_use]\n",
    "\n",
    "        data_to_predict = features_df.shift(1).dropna()\n",
    "\n",
    "        if enough_data:\n",
    "            data_to_train = data_to_predict[data_to_predict.index.year < last_year]\n",
    "            data_to_test = data_to_predict[data_to_predict.index.year >= last_year]\n",
    "        else:\n",
    "            data_to_train = data_to_predict[data_to_predict.index.year < (last_year - 1)]\n",
    "            data_to_test = data_to_predict[data_to_predict.index.year >= (last_year - 1)]\n",
    "\n",
    "        gmm = GaussianMixture(n_components=3, covariance_type='full', max_iter=1000, n_init=100)\n",
    "        if calibrate_by_weekday:\n",
    "            regime = fit_model_by_weekday(gmm, data_to_predict, data_to_train, features_to_use)\n",
    "        else:\n",
    "            model_prediction = fit_model(gmm, data_to_predict, data_to_train, features_to_use)\n",
    "            regime = pd.Series(data = model_prediction, index = data_to_predict.index).rename(\"regime\")\n",
    "            regime = regime.resample(\"5T\").asfreq().fillna(method=\"ffill\")\n",
    "\n",
    "        new_df = pd.merge(algo_df, regime, left_index=True, right_index=True)\n",
    "        new_df = new_df.astype({\"regime\":\"int32\"})\n",
    "\n",
    "        if enough_data:\n",
    "            train = new_df[new_df.index.year < last_year]\n",
    "            test = new_df[new_df.index.year >= last_year]\n",
    "        else:\n",
    "            train = new_df[new_df.index.year < (last_year - 1)]\n",
    "            test = new_df[new_df.index.year >= (last_year - 1)]\n",
    "\n",
    "        print(\"Model used: GMM, features used: [{}]\\n\".format(\", \".join(features_to_use)))\n",
    "        if static_predictor:\n",
    "            print(\"Backtesting performance of static predictor using segmented data...\\n\")\n",
    "            mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=False, regimes=new_df['regime'].unique())\n",
    "            print(\"The performance of the algorithm using static predictor with segmented data on \" + ticker + \" is\")\n",
    "            print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "            print(\"-\"*80)\n",
    "\n",
    "        if dynamic_predictor:\n",
    "            print(\"Backtesting performance of dynamic predictor using segmented data ...\\n\")\n",
    "            mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=True, regimes=new_df['regime'].unique())\n",
    "            print(\"The performance of the algorithm using dynamic predictor with segmented data on \" + ticker + \" is\")\n",
    "            print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "            print(\"-\"*80)\n",
    "\n",
    "#     hmm = GMMHMM(n_components=3, n_mix=3, covariance_type='full', n_iter=1000, random_state=100)\n",
    "        hmm = GaussianHMM(n_components=3, covariance_type='full', n_iter=1000, random_state=100)\n",
    "        if calibrate_by_weekday:\n",
    "            regime = fit_model_by_weekday(hmm, data_to_predict, data_to_train, features_to_use)\n",
    "        else:\n",
    "            model_prediction = fit_model(hmm, data_to_predict, data_to_train, features_to_use)\n",
    "            regime = pd.Series(data = model_prediction, index = data_to_predict.index).rename(\"regime\")\n",
    "            regime = regime.resample(\"5T\").asfreq().fillna(method=\"ffill\")\n",
    "\n",
    "        regime = pd.Series(data = model_prediction, index = data_to_predict.index).rename(\"regime\")\n",
    "        regime = regime.resample(\"5T\").asfreq().fillna(method=\"ffill\")\n",
    "\n",
    "        new_df = pd.merge(algo_df, regime, left_index=True, right_index=True)\n",
    "        new_df = new_df.astype({\"regime\":\"int32\"})\n",
    "\n",
    "        if enough_data:\n",
    "            train = new_df[new_df.index.year < last_year]\n",
    "            test = new_df[new_df.index.year >= last_year]\n",
    "        else:\n",
    "            train = new_df[new_df.index.year < (last_year - 1)]\n",
    "            test = new_df[new_df.index.year >= (last_year - 1)]\n",
    "\n",
    "        print(\"Model used: Gaussian HMM, features used: [{}]\\n\".format(\", \".join(features_to_use)))\n",
    "        if static_predictor:\n",
    "            print(\"Backtesting performance of static predictor using segmented data...\\n\")\n",
    "            mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=False, regimes=new_df['regime'].unique())\n",
    "            print(\"The performance of the algorithm using static predictor with segmented data on \" + ticker + \" is\")\n",
    "            print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "            print(\"-\"*80)\n",
    "\n",
    "        if dynamic_predictor:\n",
    "            print(\"Backtesting performance of dynamic predictor using segmented data...\\n\")\n",
    "            mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=True, regimes=new_df['regime'].unique())\n",
    "            print(\"The performance of the algorithm using dynamic predictor with segmented data on \" + ticker + \" is\")\n",
    "            print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "            print(\"-\"*80)\n",
    "\n",
    "    # multi_hmm = MultinomialHMM(n_components=3, n_iter=1000, random_state=100)\n",
    "    # model_prediction = fit_model(multi_hmm, data_to_predict, data_to_train, features_to_use)\n",
    "\n",
    "    # regime = pd.Series(data = model_prediction, index = data_to_predict.index).rename(\"regime\")\n",
    "    # regime = regime.resample(\"5T\").asfreq().fillna(method=\"ffill\")\n",
    "\n",
    "    # new_df = pd.merge(algo_df, regime, left_index=True, right_index=True)\n",
    "    # new_df = new_df.astype({\"regime\":\"int32\"})\n",
    "\n",
    "    # if enough_data:\n",
    "    #   train = new_df[new_df.index.year < last_year]\n",
    "    #   test = new_df[new_df.index.year >= last_year]\n",
    "    # else:\n",
    "    #   train = new_df[new_df.index.year < (last_year - 1)]\n",
    "    #   test = new_df[new_df.index.year >= (last_year - 1)]\n",
    "\n",
    "    # print(\"Model used: Multinomial HMM, features used: [{}]\\n\".format(\", \".join(features_to_use)))\n",
    "    # print(\"Backtesting performance of static predictor using segmented data...\\n\")\n",
    "    # mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=False, regimes=new_df['regime'].unique())\n",
    "    # print(\"The performance of the algorithm using static predictor with segmented data on \" + ticker + \" is\")\n",
    "    # print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "\n",
    "    # print(\"-\"*80)\n",
    "\n",
    "    # print(\"Backtesting performance of dynamic predictor using segmented data...\\n\")\n",
    "    # mean_bps_diff_buys, sd_bps_diff_buys, mean_bps_diff_sells, sd_bps_diff_sells, percentiles_diff_vwap_buys, percentiles_diff_vwap_sells = getAlgoPerformanceByRegime(train, test, dynamic_flag=True, regimes=new_df['regime'].unique())\n",
    "    # print(\"The performance of the algorithm using dynamic predictor with segmented data on \" + ticker + \" is\")\n",
    "    # print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))\n",
    "    # print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SFrOsq5qgwf"
   },
   "source": [
    "## Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "npmvM6o9NhOm"
   },
   "source": [
    "#### BMW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prueba con función otro notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on BMW is\n",
      "Mean: ±0.055855\n",
      "Standard Dev: ±1.041366\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [log_total_traded_vol, money_flow_index]\n",
      "\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.005959\n",
      "Standard Dev: ±1.333628\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [log_total_traded_vol, money_flow_index]\n",
      "\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.056958\n",
      "Standard Dev: ±1.206740\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"log_total_traded_vol\", \"money_flow_index\"], from_year=1900, static_predictor=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prueba con función otro notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on BMW is\n",
      "Mean: ±0.062248\n",
      "Standard Dev: ±1.065458\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [log_total_traded_vol, money_flow_index]\n",
      "\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.002653\n",
      "Standard Dev: ±1.336090\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [log_total_traded_vol, money_flow_index]\n",
      "\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.056958\n",
      "Standard Dev: ±1.206740\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"log_total_traded_vol\", \"money_flow_index\"], from_year=1900, static_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on BMW is\n",
      "Mean: ±0.062248\n",
      "Standard Dev: ±1.065458\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.002653\n",
      "Standard Dev: ±1.336090\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [log_total_traded_vol, money_flow_index]\n",
      "\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.056958\n",
      "Standard Dev: ±1.206740\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"log_total_traded_vol\", \"money_flow_index\"], from_year=1900, static_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on BMW is\n",
      "Mean: ±0.062248\n",
      "Standard Dev: ±1.065458\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.005959\n",
      "Standard Dev: ±1.333628\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [log_total_traded_vol, money_flow_index]\n",
      "\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.002712\n",
      "Standard Dev: ±1.070776\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"log_total_traded_vol\", \"money_flow_index\"], from_year=1900, static_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on BMW is\n",
      "Mean: ±0.062248\n",
      "Standard Dev: ±1.065458\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.014594\n",
      "Standard Dev: ±1.317188\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [log_total_traded_vol, money_flow_index]\n",
      "\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.014305\n",
      "Standard Dev: ±1.270934\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"log_total_traded_vol\", \"money_flow_index\"], from_year=1900, static_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on BMW is\n",
      "Mean: ±0.095037\n",
      "Standard Dev: ±1.237775\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [daily_log_return, short_term_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.101379\n",
      "Standard Dev: ±1.278587\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [daily_log_return, short_term_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.100298\n",
      "Standard Dev: ±1.284063\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"daily_log_return\", \"short_term_vol\"], from_year=1900, dynamic_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on BMW is\n",
      "Mean: ±0.095037\n",
      "Standard Dev: ±1.237775\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [implied_daily_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.095188\n",
      "Standard Dev: ±1.195121\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [implied_daily_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.095152\n",
      "Standard Dev: ±1.205371\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"implied_daily_vol\"], from_year=1900, dynamic_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on BMW is\n",
      "Mean: ±0.095037\n",
      "Standard Dev: ±1.237775\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [daily_log_return, implied_daily_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.105122\n",
      "Standard Dev: ±1.281672\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [daily_log_return, implied_daily_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.095179\n",
      "Standard Dev: ±1.205436\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"daily_log_return\", \"implied_daily_vol\"], from_year=1900, dynamic_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on BMW is\n",
      "Mean: ±0.095037\n",
      "Standard Dev: ±1.237775\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [daily_log_return]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.086808\n",
      "Standard Dev: ±1.233850\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [daily_log_return]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.111172\n",
      "Standard Dev: ±1.286845\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"daily_log_return\"], from_year=1900, dynamic_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 319522,
     "status": "error",
     "timestamp": 1583521427084,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "P4TyvkLSTFEY",
    "outputId": "b96e6dcd-ad13-4cb3-9a48-80e2d25d820f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on BMW is\n",
      "Mean: ±0.095037\n",
      "Standard Dev: ±1.237775\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on BMW is\n",
      "Mean: ±0.062248\n",
      "Standard Dev: ±1.065458\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.087754\n",
      "Standard Dev: ±1.310582\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.014594\n",
      "Standard Dev: ±1.317188\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.095799\n",
      "Standard Dev: ±1.266043\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BMW is\n",
      "Mean: ±0.014305\n",
      "Standard Dev: ±1.270934\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BMW_BMW.txt\", \"BMW\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tV-XojmyPDcj"
   },
   "source": [
    "### BBVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 366036,
     "status": "error",
     "timestamp": 1583521870549,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "dBXTdQ4pTB0a",
    "outputId": "47f955bd-76de-426e-ad86-a964b7e33616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2000\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on BBVA is\n",
      "Mean: ±0.092277\n",
      "Standard Dev: ±1.361710\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on BBVA is\n",
      "Mean: ±0.058314\n",
      "Standard Dev: ±0.949860\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BBVA is\n",
      "Mean: ±0.088251\n",
      "Standard Dev: ±1.358629\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BBVA is\n",
      "Mean: ±0.098708\n",
      "Standard Dev: ±1.093188\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on BBVA is\n",
      "Mean: ±0.094301\n",
      "Standard Dev: ±1.371007\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on BBVA is\n",
      "Mean: ±0.076502\n",
      "Standard Dev: ±1.086856\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a6166dac0f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintFullAlgoPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BBVA_MC.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BBVA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"money_flow_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log_total_traded_vol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_year\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d8b382b8a381>\u001b[0m in \u001b[0;36mprintFullAlgoPerformance\u001b[0;34m(file, ticker, features_to_use, normal_vwap, machine_learning, from_year)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mmulti_hmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mmodel_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_hmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_to_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_to_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mregime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_to_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"regime\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2850da32ae01>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, full_data, train_data, list_of_features)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m     \u001b[0mX_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0mX_full_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \"\"\"\n\u001b[1;32m    461\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hmmlearn/hmm.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_and_set_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hmmlearn/hmm.py\u001b[0m in \u001b[0;36m_check_and_set_n_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Symbols should be integers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Symbols should be nonnegative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Symbols should be integers"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"BBVA_MC.txt\", \"BBVA\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fls2IBlqPxuz"
   },
   "source": [
    "### Vivendi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 411708,
     "status": "ok",
     "timestamp": 1583522327930,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "Mfm5Ssf_PzUx",
    "outputId": "a2689529-f496-42b9-9fa6-fc2b75ce78f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Vivendi is\n",
      "Mean: ±0.037385\n",
      "Standard Dev: ±0.918880\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on Vivendi is\n",
      "Mean: ±0.073474\n",
      "Standard Dev: ±0.784894\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Vivendi is\n",
      "Mean: ±0.036503\n",
      "Standard Dev: ±0.923523\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Vivendi is\n",
      "Mean: ±0.044522\n",
      "Standard Dev: ±0.837037\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Vivendi is\n",
      "Mean: ±0.051276\n",
      "Standard Dev: ±0.939257\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Vivendi is\n",
      "Mean: ±0.092136\n",
      "Standard Dev: ±0.836125\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"VIVENDI.txt\", \"Vivendi\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyt11VS-QuT4"
   },
   "source": [
    "### TESCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332197,
     "status": "ok",
     "timestamp": 1583522668650,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "t_llVL8tQxIX",
    "outputId": "7a4d3279-19e8-4a7c-b090-bb056e9ec7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2008\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Tesco is\n",
      "Mean: ±0.045996\n",
      "Standard Dev: ±0.828027\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on Tesco is\n",
      "Mean: ±0.148551\n",
      "Standard Dev: ±1.071701\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Tesco is\n",
      "Mean: ±0.049749\n",
      "Standard Dev: ±0.839903\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Tesco is\n",
      "Mean: ±0.132413\n",
      "Standard Dev: ±1.001585\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Tesco is\n",
      "Mean: ±0.038411\n",
      "Standard Dev: ±0.829552\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Tesco is\n",
      "Mean: ±0.127656\n",
      "Standard Dev: ±1.048742\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"TESCO.txt\", \"Tesco\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTq7-s19SU5C"
   },
   "source": [
    "### TELEFONICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 448746,
     "status": "ok",
     "timestamp": 1583523147510,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "U2OfK4h8Sj_W",
    "outputId": "3bc80a7c-4c3f-40cc-dc8d-2fe30d2f2172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2001\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Telefonica is\n",
      "Mean: ±0.002406\n",
      "Standard Dev: ±0.797528\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on Telefonica is\n",
      "Mean: ±0.078622\n",
      "Standard Dev: ±1.528175\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Telefonica is\n",
      "Mean: ±0.018784\n",
      "Standard Dev: ±0.799085\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Telefonica is\n",
      "Mean: ±0.023504\n",
      "Standard Dev: ±0.688103\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Telefonica is\n",
      "Mean: ±0.022458\n",
      "Standard Dev: ±0.823479\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Telefonica is\n",
      "Mean: ±0.043970\n",
      "Standard Dev: ±0.708673\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"TEF.txt\", \"Telefonica\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8YXurfKUHzE"
   },
   "source": [
    "### NOKIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422166,
     "status": "ok",
     "timestamp": 1583523645841,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "QXkpIHR3ULwE",
    "outputId": "240d69b1-c37b-4bd8-eb57-25afa32cb93e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Nokia is\n",
      "Mean: ±0.053665\n",
      "Standard Dev: ±1.141943\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on Nokia is\n",
      "Mean: ±0.119720\n",
      "Standard Dev: ±1.618934\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Nokia is\n",
      "Mean: ±0.060769\n",
      "Standard Dev: ±1.172547\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Nokia is\n",
      "Mean: ±0.125878\n",
      "Standard Dev: ±1.747559\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Nokia is\n",
      "Mean: ±0.055474\n",
      "Standard Dev: ±1.176902\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Nokia is\n",
      "Mean: ±0.125874\n",
      "Standard Dev: ±1.793025\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"NOKIA.txt\", \"Nokia\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZzSEwD7US0M"
   },
   "source": [
    "### GSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 348215,
     "status": "ok",
     "timestamp": 1583524532202,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "y-xbi-sAUVs7",
    "outputId": "1b28b413-951a-4a9a-af4a-0b63cb322473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2008\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on GSK is\n",
      "Mean: ±0.015963\n",
      "Standard Dev: ±0.689863\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on GSK is\n",
      "Mean: ±0.058979\n",
      "Standard Dev: ±0.770256\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on GSK is\n",
      "Mean: ±0.003239\n",
      "Standard Dev: ±0.689950\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on GSK is\n",
      "Mean: ±0.088892\n",
      "Standard Dev: ±0.857065\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on GSK is\n",
      "Mean: ±0.011170\n",
      "Standard Dev: ±0.684722\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on GSK is\n",
      "Mean: ±0.065093\n",
      "Standard Dev: ±1.013643\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"GSK.txt\", \"GSK\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5S4MF19TUcPk"
   },
   "source": [
    "### DIAGEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 685470,
     "status": "ok",
     "timestamp": 1583524869880,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "uxSIYj9hUdVk",
    "outputId": "ac9036ae-5f11-46fe-e810-47f42b65b5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2008\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Diageo is\n",
      "Mean: ±0.143363\n",
      "Standard Dev: ±0.557072\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on Diageo is\n",
      "Mean: ±0.092379\n",
      "Standard Dev: ±0.596173\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Diageo is\n",
      "Mean: ±0.140762\n",
      "Standard Dev: ±0.566523\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Diageo is\n",
      "Mean: ±0.073340\n",
      "Standard Dev: ±0.764259\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Diageo is\n",
      "Mean: ±0.147154\n",
      "Standard Dev: ±0.574141\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Diageo is\n",
      "Mean: ±0.071617\n",
      "Standard Dev: ±0.757904\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"DIAGEO.txt\", \"Diageo\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpD0z86OUfjL"
   },
   "source": [
    "### COMMERZBANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1117022,
     "status": "ok",
     "timestamp": 1583525301803,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "_xlHIIixUg6k",
    "outputId": "3ddeb814-b724-4a2f-f190-2e9d8f213200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Commerzbank is\n",
      "Mean: ±0.256454\n",
      "Standard Dev: ±2.549025\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on Commerzbank is\n",
      "Mean: ±0.133939\n",
      "Standard Dev: ±5.018480\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Commerzbank is\n",
      "Mean: ±0.247826\n",
      "Standard Dev: ±2.701519\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Commerzbank is\n",
      "Mean: ±0.215639\n",
      "Standard Dev: ±1.978990\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Commerzbank is\n",
      "Mean: ±0.248258\n",
      "Standard Dev: ±2.697174\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Commerzbank is\n",
      "Mean: ±0.215094\n",
      "Standard Dev: ±1.975645\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"COMMERZBANK.txt\", \"Commerzbank\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbFn73POUx0z"
   },
   "source": [
    "### AIRBUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1770332,
     "status": "ok",
     "timestamp": 1583525955973,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "HecZ0QbWUzFb",
    "outputId": "efc4bc57-9c08-4a26-f702-372430409022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2003\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Airbus is\n",
      "Mean: ±0.024169\n",
      "Standard Dev: ±1.003630\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor on Airbus is\n",
      "Mean: ±0.008608\n",
      "Standard Dev: ±1.051960\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: GMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Airbus is\n",
      "Mean: ±0.029627\n",
      "Standard Dev: ±1.120599\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data ...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Airbus is\n",
      "Mean: ±0.017528\n",
      "Standard Dev: ±0.959905\n",
      "--------------------------------------------------------------------------------\n",
      "Model used: Gaussian HMM, features used: [money_flow_index, log_total_traded_vol]\n",
      "\n",
      "Backtesting performance of static predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using static predictor with segmented data on Airbus is\n",
      "Mean: ±0.031370\n",
      "Standard Dev: ±1.113171\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance of dynamic predictor using segmented data...\n",
      "\n",
      "The performance of the algorithm using dynamic predictor with segmented data on Airbus is\n",
      "Mean: ±0.011961\n",
      "Standard Dev: ±0.969725\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"AIR_AIRBUS.txt\", \"Airbus\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IeTK_liU4Vq"
   },
   "source": [
    "### NOVARTIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525,
     "resources": {
      "http://localhost:8080/f/?l=https://mocdfcye2jc-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20200305-085600-RC00_299114455": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1788833,
     "status": "error",
     "timestamp": 1583525975352,
     "user": {
      "displayName": "Míguel Sánchez Jiménez",
      "photoUrl": "",
      "userId": "04995178406211197766"
     },
     "user_tz": -60
    },
    "id": "Uf2femQMU55q",
    "outputId": "f278d43e-bf6f-4123-ae6a-58539b50b0f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2008\n",
      "\n",
      "Backtesting performance with static predictor...\n",
      "\n",
      "The performance of the algorithm using static predictor on Novartis is\n",
      "Mean: ±0.064624\n",
      "Standard Dev: ±0.604136\n",
      "--------------------------------------------------------------------------------\n",
      "Backtesting performance with dynamic predictor...\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5ed941ba4d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintFullAlgoPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NOVARTIS.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Novartis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"money_flow_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log_total_traded_vol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_year\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-de1945d1aaa8>\u001b[0m in \u001b[0;36mprintFullAlgoPerformance\u001b[0;34m(file, ticker, features_to_use, normal_vwap, machine_learning, from_year)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Backtesting performance with dynamic predictor...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmean_bps_diff_buys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd_bps_diff_buys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_bps_diff_sells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd_bps_diff_sells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentiles_diff_vwap_buys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentiles_diff_vwap_sells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAlgoPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The performance of the algorithm using dynamic predictor on \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean: ±%f\\nStandard Dev: ±%f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_bps_diff_buys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd_bps_diff_buys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2850da32ae01>\u001b[0m in \u001b[0;36mgetAlgoPerformance\u001b[0;34m(training_data, test_data, dynamic_flag)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdynamic_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mbacktest_buy_vwap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacktest_sell_vwap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktestAlgoDynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvMedian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstaticVolPredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mbacktest_buy_vwap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacktest_sell_vwap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktestAlgoStatic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvMedian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstaticVolPredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2850da32ae01>\u001b[0m in \u001b[0;36mbacktestAlgoDynamic\u001b[0;34m(training_data, test_data, advMedian, staticVolPredictor)\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0mnew_training_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataToMultiIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m   \u001b[0mnew_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataToMultiIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m   \u001b[0mreversedCumVol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetReversedCumVol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_training_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m   \u001b[0mvolPredictorNextBin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetVolPredictorNextBin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstaticVolPredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvMedian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2850da32ae01>\u001b[0m in \u001b[0;36mgetReversedCumVol\u001b[0;34m(multi_data, data)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mreversed_cumvol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0mreversed_cumvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed_cumvol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mreversed_cumvol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    300\u001b[0m                         raise ValueError(\n\u001b[1;32m    301\u001b[0m                             \u001b[0;34m\"Length of passed values is {val}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0;34m\"index implies {ind}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                         )\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 2620, index implies 267237"
     ]
    }
   ],
   "source": [
    "printFullAlgoPerformance(\"NOVARTIS.txt\", \"Novartis\", [\"money_flow_index\", \"log_total_traded_vol\"], from_year=1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDjXmz4bVyP6"
   },
   "source": [
    "## Test all files with daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCbpfHEK-ayu"
   },
   "outputs": [],
   "source": [
    "for r, d, f in os.walk(\"/\"+DATAPATH+\"/\"):\n",
    "  for file in f:\n",
    "    if \".txt\" in file:\n",
    "      printFullAlgoPerformance(file, file.split(\".\")[0], [\"daily_log_return\"], from_year=1900, dynamic_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\Data\\\\E-MINI-SP500.txt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6A8bh2kPGgDY"
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(DATAPATH, \"E-MINI-SP500.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5p0JMJLeOOmG"
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 3] The system cannot find the path specified: '\\\\.\\\\Data\\\\E-MINI-SP500.txt'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen_local_file\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1472\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m             \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1474\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '\\\\.\\\\Data\\\\E-MINI-SP500.txt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5c7af074bdf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"file:///\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<DTYYYYMMDD>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'<TIME>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[1;32m--> 440\u001b[1;33m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m     )\n\u001b[0;32m    442\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mfile_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1449\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"file:// scheme is supported only on localhost\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1451\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_local_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[1;31m# names for the localhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen_local_file\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1488\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0maddinfourl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigurl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1490\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1491\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file not on local host'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 3] The system cannot find the path specified: '\\\\.\\\\Data\\\\E-MINI-SP500.txt'>"
     ]
    }
   ],
   "source": [
    "emini = pd.read_csv(\"file:///\" + filepath, parse_dates=[['<DTYYYYMMDD>', '<TIME>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"file:///\" + os.path.join(DATAPATH, \"AAPL.txt\"), parse_dates=[['<DTYYYYMMDD>', '<TIME>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGtble9tOec7"
   },
   "outputs": [],
   "source": [
    "apple = formatData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2001-01-02 09:32:00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.07</td>\n",
       "      <td>989800</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>09:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001-01-02 09:33:00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.07</td>\n",
       "      <td>205800</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>09:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001-01-02 09:34:00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.07</td>\n",
       "      <td>644000</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>09:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001-01-02 09:35:00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.07</td>\n",
       "      <td>404600</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>09:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001-01-02 09:36:00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>771400</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>09:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-06 15:56:00</td>\n",
       "      <td>289.04</td>\n",
       "      <td>289.64</td>\n",
       "      <td>288.79</td>\n",
       "      <td>288.81</td>\n",
       "      <td>209965</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>15:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-06 15:57:00</td>\n",
       "      <td>288.82</td>\n",
       "      <td>289.67</td>\n",
       "      <td>288.82</td>\n",
       "      <td>289.63</td>\n",
       "      <td>231190</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>15:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-06 15:58:00</td>\n",
       "      <td>289.61</td>\n",
       "      <td>290.82</td>\n",
       "      <td>289.56</td>\n",
       "      <td>289.83</td>\n",
       "      <td>420556</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>15:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-06 15:59:00</td>\n",
       "      <td>289.81</td>\n",
       "      <td>290.12</td>\n",
       "      <td>289.31</td>\n",
       "      <td>289.46</td>\n",
       "      <td>335329</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-06 16:00:00</td>\n",
       "      <td>289.49</td>\n",
       "      <td>289.52</td>\n",
       "      <td>288.33</td>\n",
       "      <td>288.95</td>\n",
       "      <td>3669565</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1856938 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close   volume       date  \\\n",
       "date_time                                                                 \n",
       "2001-01-02 09:32:00    1.06    1.07    1.06    1.07   989800 2001-01-02   \n",
       "2001-01-02 09:33:00    1.07    1.07    1.06    1.07   205800 2001-01-02   \n",
       "2001-01-02 09:34:00    1.07    1.07    1.06    1.07   644000 2001-01-02   \n",
       "2001-01-02 09:35:00    1.07    1.07    1.06    1.07   404600 2001-01-02   \n",
       "2001-01-02 09:36:00    1.07    1.07    1.06    1.06   771400 2001-01-02   \n",
       "...                     ...     ...     ...     ...      ...        ...   \n",
       "2020-03-06 15:56:00  289.04  289.64  288.79  288.81   209965 2020-03-06   \n",
       "2020-03-06 15:57:00  288.82  289.67  288.82  289.63   231190 2020-03-06   \n",
       "2020-03-06 15:58:00  289.61  290.82  289.56  289.83   420556 2020-03-06   \n",
       "2020-03-06 15:59:00  289.81  290.12  289.31  289.46   335329 2020-03-06   \n",
       "2020-03-06 16:00:00  289.49  289.52  288.33  288.95  3669565 2020-03-06   \n",
       "\n",
       "                         time  \n",
       "date_time                      \n",
       "2001-01-02 09:32:00  09:32:00  \n",
       "2001-01-02 09:33:00  09:33:00  \n",
       "2001-01-02 09:34:00  09:34:00  \n",
       "2001-01-02 09:35:00  09:35:00  \n",
       "2001-01-02 09:36:00  09:36:00  \n",
       "...                       ...  \n",
       "2020-03-06 15:56:00  15:56:00  \n",
       "2020-03-06 15:57:00  15:57:00  \n",
       "2020-03-06 15:58:00  15:58:00  \n",
       "2020-03-06 15:59:00  15:59:00  \n",
       "2020-03-06 16:00:00  16:00:00  \n",
       "\n",
       "[1856938 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_traded_vol = np.exp(get_log(get_total_traded_vol(apple))[VOLUME]).rename(\"log_total_traded_vol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2001-01-02    108355800\n",
       "2001-01-03    195965000\n",
       "2001-01-04    174483400\n",
       "2001-01-05     96156200\n",
       "2001-01-08     88020800\n",
       "                ...    \n",
       "2020-03-02     59736664\n",
       "2020-03-03     52706848\n",
       "2020-03-04     39823037\n",
       "2020-03-05     35286759\n",
       "2020-03-06     38827169\n",
       "Name: volume, Length: 4821, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple.groupby(\"date\").sum()[VOLUME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2001-01-03    195965000.0\n",
       "2001-01-04    174483400.0\n",
       "2001-01-05     96156200.0\n",
       "2001-01-08     88020800.0\n",
       "2001-01-09    139378400.0\n",
       "                 ...     \n",
       "2020-03-02     59736664.0\n",
       "2020-03-03     52706848.0\n",
       "2020-03-04     39823037.0\n",
       "2020-03-05     35286759.0\n",
       "2020-03-06     38827169.0\n",
       "Freq: B, Name: log_total_traded_vol, Length: 5003, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_traded_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting BMW. Using data from 2003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ticker = \"BMW\"\n",
    "from_year = 1900\n",
    "filepath = os.path.join(DATAPATH, \"BMW_BMW.txt\")\n",
    "df = pd.read_csv(\"file:///\" + filepath, parse_dates=[['<DTYYYYMMDD>', '<TIME>']])\n",
    "formatted_df = formatData(df)\n",
    "\n",
    "first_year = formatted_df.index[0].year\n",
    "if from_year >= first_year:\n",
    "    formatted_df = formatted_df[formatted_df.index.year >= from_year]\n",
    "\n",
    "print(\"Backtesting {}. Using data from {}\\n\".format(ticker, formatted_df.index[0].year))\n",
    "\n",
    "enough_data = True\n",
    "\n",
    "last_year = formatted_df.index.year.unique()[-1]\n",
    "algo_df = prepareDataframe(formatted_df)\n",
    "train = algo_df[algo_df.index.year < last_year]\n",
    "test = algo_df[algo_df.index.year >= last_year]\n",
    "\n",
    "## If test data has less than 150 business days, use previous year\n",
    "if len(test) < 150*102:\n",
    "    train = algo_df[algo_df.index.year < (last_year - 1)]\n",
    "    test = algo_df[algo_df.index.year >= (last_year - 1)]\n",
    "    enough_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>volume*price</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2003-06-20 09:00:00</td>\n",
       "      <td>127.45</td>\n",
       "      <td>127.51</td>\n",
       "      <td>127.05</td>\n",
       "      <td>127.34</td>\n",
       "      <td>19577</td>\n",
       "      <td>623660.90</td>\n",
       "      <td>31.856817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-06-20 09:05:00</td>\n",
       "      <td>126.82</td>\n",
       "      <td>126.93</td>\n",
       "      <td>126.73</td>\n",
       "      <td>126.88</td>\n",
       "      <td>19388</td>\n",
       "      <td>614962.85</td>\n",
       "      <td>31.718736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-06-20 09:10:00</td>\n",
       "      <td>158.48</td>\n",
       "      <td>158.54</td>\n",
       "      <td>158.45</td>\n",
       "      <td>158.53</td>\n",
       "      <td>12301</td>\n",
       "      <td>390105.50</td>\n",
       "      <td>31.713316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-06-20 09:15:00</td>\n",
       "      <td>158.53</td>\n",
       "      <td>158.63</td>\n",
       "      <td>158.48</td>\n",
       "      <td>158.63</td>\n",
       "      <td>10060</td>\n",
       "      <td>319272.22</td>\n",
       "      <td>31.736801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-06-20 09:20:00</td>\n",
       "      <td>127.50</td>\n",
       "      <td>127.62</td>\n",
       "      <td>127.42</td>\n",
       "      <td>127.46</td>\n",
       "      <td>25388</td>\n",
       "      <td>809844.84</td>\n",
       "      <td>31.898725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-11 17:05:00</td>\n",
       "      <td>323.53</td>\n",
       "      <td>323.64</td>\n",
       "      <td>323.46</td>\n",
       "      <td>323.60</td>\n",
       "      <td>24024</td>\n",
       "      <td>1555564.96</td>\n",
       "      <td>64.750456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-11 17:10:00</td>\n",
       "      <td>323.91</td>\n",
       "      <td>323.96</td>\n",
       "      <td>323.81</td>\n",
       "      <td>323.87</td>\n",
       "      <td>15016</td>\n",
       "      <td>972629.02</td>\n",
       "      <td>64.772844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-11 17:15:00</td>\n",
       "      <td>324.06</td>\n",
       "      <td>324.18</td>\n",
       "      <td>323.98</td>\n",
       "      <td>324.03</td>\n",
       "      <td>33398</td>\n",
       "      <td>2164312.07</td>\n",
       "      <td>64.803643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-11 17:20:00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>324.15</td>\n",
       "      <td>323.92</td>\n",
       "      <td>324.04</td>\n",
       "      <td>55348</td>\n",
       "      <td>3585546.75</td>\n",
       "      <td>64.781867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-11 17:25:00</td>\n",
       "      <td>324.12</td>\n",
       "      <td>324.22</td>\n",
       "      <td>324.02</td>\n",
       "      <td>324.13</td>\n",
       "      <td>56676</td>\n",
       "      <td>3674304.05</td>\n",
       "      <td>64.829982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434112 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close  volume  volume*price  \\\n",
       "date_time                                                                   \n",
       "2003-06-20 09:00:00  127.45  127.51  127.05  127.34   19577     623660.90   \n",
       "2003-06-20 09:05:00  126.82  126.93  126.73  126.88   19388     614962.85   \n",
       "2003-06-20 09:10:00  158.48  158.54  158.45  158.53   12301     390105.50   \n",
       "2003-06-20 09:15:00  158.53  158.63  158.48  158.63   10060     319272.22   \n",
       "2003-06-20 09:20:00  127.50  127.62  127.42  127.46   25388     809844.84   \n",
       "...                     ...     ...     ...     ...     ...           ...   \n",
       "2019-10-11 17:05:00  323.53  323.64  323.46  323.60   24024    1555564.96   \n",
       "2019-10-11 17:10:00  323.91  323.96  323.81  323.87   15016     972629.02   \n",
       "2019-10-11 17:15:00  324.06  324.18  323.98  324.03   33398    2164312.07   \n",
       "2019-10-11 17:20:00  324.00  324.15  323.92  324.04   55348    3585546.75   \n",
       "2019-10-11 17:25:00  324.12  324.22  324.02  324.13   56676    3674304.05   \n",
       "\n",
       "                          vwap  \n",
       "date_time                       \n",
       "2003-06-20 09:00:00  31.856817  \n",
       "2003-06-20 09:05:00  31.718736  \n",
       "2003-06-20 09:10:00  31.713316  \n",
       "2003-06-20 09:15:00  31.736801  \n",
       "2003-06-20 09:20:00  31.898725  \n",
       "...                        ...  \n",
       "2019-10-11 17:05:00  64.750456  \n",
       "2019-10-11 17:10:00  64.772844  \n",
       "2019-10-11 17:15:00  64.803643  \n",
       "2019-10-11 17:20:00  64.781867  \n",
       "2019-10-11 17:25:00  64.829982  \n",
       "\n",
       "[434112 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOXpXMQtvquFu1aIlvY40BX",
   "collapsed_sections": [
    "8SFrOsq5qgwf",
    "npmvM6o9NhOm",
    "tV-XojmyPDcj",
    "VbFn73POUx0z"
   ],
   "name": "Backtesting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
