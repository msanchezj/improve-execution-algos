{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM, MultinomialHMM\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_TIME = 'date_time'\n",
    "DATE = 'date'\n",
    "TIME = 'time'\n",
    "OPEN_PRICE = 'open'\n",
    "HIGH_PRICE = 'high'\n",
    "LOW_PRICE = 'low'\n",
    "CLOSE_PRICE = 'close'\n",
    "VOLUME = 'volume'\n",
    "TURNOVER = 'turnover'\n",
    "VWAP = 'vwap'\n",
    "FEATURES = ['high_low_spread', \"open_close_rets\", \"log_total_traded_vol\", \"daily_log_return\", \"short_term_vol\", \"long_term_vol\", \"money_flow_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "DATAPATH = os.getcwd()+\"\\\\Data\\\\\"\n",
    "\n",
    "files_list = []\n",
    "for root, dirs, files in os.walk(DATAPATH):\n",
    "    for file in files:\n",
    "        files_list.append(file)\n",
    "        \n",
    "raw = pd.read_csv(\"file:///\" + os.path.join(DATAPATH, files_list[3]), parse_dates=[['<DTYYYYMMDD>', '<TIME>']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input vieja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df.drop(labels=[\"<TICKER>\", \"<PER>\", \"<OPENINT>\"], axis=\"columns\", inplace=True)\n",
    "    returned_df.columns = ['date_time', 'open', 'high', 'low', 'close', 'volume']\n",
    "    returned_df.set_index('date_time', drop=True, inplace=True)\n",
    "    returned_df = addDateAndTime(returned_df)\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "def prepareDataframe(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df['volume*price'] = returned_df['volume']*returned_df['close']\n",
    "    returned_df = returned_df.resample('5T').sum()\n",
    "    returned_df = returned_df.between_time('9:00', '17:34')\n",
    "    returned_df = returned_df[returned_df.index.weekday != 5]\n",
    "    returned_df = returned_df[returned_df.index.weekday != 6]\n",
    "    returned_df['vwap'] = returned_df['volume*price']/returned_df['volume']\n",
    "    returned_df.dropna(inplace=True)\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "def addDateAndTime(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df['date'] = pd.to_datetime(returned_df.index.date)\n",
    "    returned_df['time'] = pd.to_datetime(returned_df.index, format = \"%m-%d-%Y %H:%M:%S\")\n",
    "    returned_df['time'] = returned_df['time'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "formatted_df = formatData(raw)\n",
    "algo_df = prepareDataframe(formatted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df.drop(labels=[\"<PER>\", \"<OPENINT>\"], axis=\"columns\", inplace=True)\n",
    "    returned_df.columns = ['date_time', 'ticker', 'open', 'high', 'low', 'close', 'volume']\n",
    "    returned_df.set_index('date_time', drop=True, inplace=True)\n",
    "    returned_df = add_datetime(returned_df)\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "def get_open_close_time(df):\n",
    "    open_time = df.time.min()\n",
    "    close_time = df.time.max()\n",
    "    \n",
    "    return open_time, close_time\n",
    "\n",
    "def get_open_close_auction_time(df):\n",
    "    open_time = df.time.min()\n",
    "    auction_time = df.time.max()\n",
    "    close_time = df[df[TIME] != df.time.max()].time.max()\n",
    "    \n",
    "    return open_time, close_time, auction_time\n",
    "\n",
    "def get_intraday_data(df, start_time, end_time):\n",
    "    df = df.between_time(open_time, end_time)\n",
    "    df[TURNOVER] = df[VOLUME]*df[CLOSE_PRICE]\n",
    "    df_resampled = df.resample('5T').agg({OPEN_PRICE: \"first\", \n",
    "                                          LOW_PRICE: \"min\", \n",
    "                                          HIGH_PRICE: \"max\", \n",
    "                                          CLOSE_PRICE: \"last\", \n",
    "                                          VOLUME: \"sum\", \n",
    "                                          TURNOVER: \"sum\"})\n",
    "    df_resampled[VWAP] = df_resampled[TURNOVER]/df_resampled[VOLUME]\n",
    "    df_resampled = df_resampled[(df_resampled.index.weekday != 5) | (df_resampled.index.weekday != 6)]\n",
    "    df_resampled.dropna(inplace=True)\n",
    "\n",
    "    return df_resampled\n",
    "\n",
    "def get_daily_data(df):\n",
    "    daily_data = df.resample('B').agg({OPEN_PRICE: \"first\", \n",
    "                                                LOW_PRICE: \"min\",\n",
    "                                                HIGH_PRICE: \"max\", \n",
    "                                                CLOSE_PRICE: \"last\", \n",
    "                                                VOLUME: \"sum\", \n",
    "                                                TURNOVER: \"sum\"})\n",
    "    daily_data[VWAP] = daily_data.turnover/daily_data.volume\n",
    "    daily_data = daily_data[daily_data[VOLUME] > 0.1]\n",
    "    daily_data = daily_data[(daily_data.index != 6) & (daily_data.index != 7)]\n",
    "    daily_data.index = pd.to_datetime(daily_data.index)\n",
    "    daily_data = daily_data.resample('B').first()\n",
    "    daily_data.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "    return daily_data\n",
    "\n",
    "def add_datetime(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df['date'] = pd.to_datetime(returned_df.index.date)\n",
    "    returned_df['time'] = pd.to_datetime(returned_df.index, format = \"%m-%d-%Y %H:%M:%S\")\n",
    "    returned_df['time'] = returned_df['time'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "input_new = format_data(raw)\n",
    "open_time, close_time, auction_time = get_open_close_auction_time(input_new)\n",
    "intraday_data = get_intraday_data(input_new, open_time, close_time)\n",
    "daily_data = get_daily_data(intraday_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features df old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_traded_vol(df):\n",
    "    total_traded_vol = df.resample('B').sum()[['volume']]\n",
    "    total_traded_vol.drop(labels=total_traded_vol.index.get_values()[0], axis='index', inplace=True)\n",
    "\n",
    "    return total_traded_vol\n",
    "\n",
    "def get_log_open_close_returns_(df):\n",
    "    # open_close_returns = df[(df['time'] == '09:01:00') | (df['time'] == '17:35:00')]\n",
    "    open_close_returns = df[(df['time'] == '09:00:00') | (df['time'] == '17:35:00')]\n",
    "    open_close_returns['return'] = (open_close_returns['open']/open_close_returns['close'].shift(-1))\n",
    "    open_close_returns['log_return'] = np.log(open_close_returns['return'])\n",
    "    # open_close_returns = open_close_returns[open_close_returns['time'] == '09:01:00']\n",
    "    open_close_returns = open_close_returns[open_close_returns['time'] == '09:00:00']\n",
    "    open_close_returns = open_close_returns[['log_return']].resample('B').sum()\n",
    "\n",
    "    return open_close_returns\n",
    "\n",
    "def get_log_open_close_returns(df):\n",
    "    open_price = df[OPEN_PRICE].resample('B').first()\n",
    "    close_price = df[CLOSE_PRICE].resample('B').last()\n",
    "    open_close_returns = np.log(open_price/close_price.shift(-1)).dropna()\n",
    "\n",
    "    return open_close_returns\n",
    "\n",
    "def get_log_returns(df):\n",
    "    close = df[CLOSE_PRICE].resample('B').last()\n",
    "    log_daily_returns = np.log(close/close.shift(-1))\n",
    "\n",
    "    return log_daily_returns\n",
    "\n",
    "def get_high_low_spread(df):\n",
    "    daily_high = df.resample(\"B\").max()[['high']]\n",
    "    daily_low = df.resample(\"B\").min()[['low']]\n",
    "    high_low_spread = (daily_high['high']-daily_low['low'])\n",
    "\n",
    "    return high_low_spread\n",
    "\n",
    "def get_log(df):\n",
    "    return np.log(df)\n",
    "\n",
    "def get_money_flow_index(df):\n",
    "    close = df[CLOSE_PRICE].resample('B').last()\n",
    "    high = df[HIGH_PRICE].resample('B').max()\n",
    "    low = df[LOW_PRICE].resample('B').min()\n",
    "    typical_price = (close+high+low)/3\n",
    "    volume = df[VOLUME].resample('B').sum()\n",
    "    money_flow_index = typical_price/volume\n",
    "\n",
    "    return money_flow_index\n",
    "\n",
    "features_to_use = [\"log_total_traded_vol\", \"money_flow_index\"]\n",
    "\n",
    "high_low = get_log(np.abs(get_high_low_spread(formatted_df))).rename(\"high_low_spread\")\n",
    "open_close_log_rets = get_log_open_close_returns(formatted_df).rename(\"open_close_rets\")\n",
    "total_traded_vol = get_log(get_total_traded_vol(formatted_df))[VOLUME].rename(\"log_total_traded_vol\")\n",
    "daily_log_rets = get_log_returns(formatted_df).rename(\"daily_log_return\").dropna()\n",
    "short_term_vol = daily_log_rets.rolling(21).std().dropna().rename(\"short_term_vol\")\n",
    "#     short_term_vol = daily_log_rets.rolling(252).std().dropna().apply(lambda x: x/np.sqrt(21)).rename(\"short_term_vol\")\n",
    "long_term_vol = daily_log_rets.dropna().rolling(252).std(ddof=0).dropna().rename(\"long_term_vol\")\n",
    "implied_daily_vol = (daily_log_rets.dropna().rolling(252).std(ddof=0).dropna()/np.sqrt(252)).rename(\"implied_daily_vol\")\n",
    "mfi = get_money_flow_index(formatted_df).rename(\"money_flow_index\")\n",
    "\n",
    "features_df = pd.concat([high_low, open_close_log_rets, total_traded_vol, daily_log_rets, short_term_vol, long_term_vol, mfi, implied_daily_vol], axis=1).dropna()\n",
    "features_df = features_df.replace([np.inf, -np.inf], np.nan)\n",
    "features_df = features_df.dropna()\n",
    "# features_df = features_df[features_df['log_return'] != 0.0]\n",
    "# features_df = features_df[features_df['hl_spread'] != 0.0]\n",
    "features_df = features_df[features_to_use]\n",
    "\n",
    "data_to_predict = features_df.shift(1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_total_traded_vol</th>\n",
       "      <th>money_flow_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2004-06-24</td>\n",
       "      <td>14.379688</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>14.710144</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-06-28</td>\n",
       "      <td>14.210634</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-06-29</td>\n",
       "      <td>14.781439</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-06-30</td>\n",
       "      <td>15.000944</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>14.192709</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>14.541612</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>13.731285</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>14.051481</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>13.742699</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            log_total_traded_vol  money_flow_index\n",
       "date_time                                         \n",
       "2004-06-24             14.379688          0.000020\n",
       "2004-06-25             14.710144          0.000015\n",
       "2004-06-28             14.210634          0.000024\n",
       "2004-06-29             14.781439          0.000014\n",
       "2004-06-30             15.000944          0.000011\n",
       "...                          ...               ...\n",
       "2019-10-04             14.192709          0.000044\n",
       "2019-10-07             14.541612          0.000030\n",
       "2019-10-08             13.731285          0.000068\n",
       "2019-10-09             14.051481          0.000049\n",
       "2019-10-10             13.742699          0.000067\n",
       "\n",
       "[3822 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_series_list(daily_data):\n",
    "    log_returns = get_log_returns(daily_data)\n",
    "    adv_antilog = get_antilog_adv_median(daily_data)\n",
    "    mfi = get_money_flow_index(daily_data)\n",
    "    betas_mkt_impact = get_beta_market_impact(daily_data)\n",
    "    log_traded_vol = get_log_total_trade_vol(daily_data)\n",
    "    \n",
    "    features = [log_returns, adv_antilog, mfi, betas_mkt_impact, log_traded_vol]\n",
    "    features_df.rename(columns={VOLUME: \"log_total_traded_vol\"}, inplace=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_features_df(list_of_features):\n",
    "    features_df = pd.concat(list_of_features, axis=1).dropna()\n",
    "    features_df = features_df.replace([np.inf, -np.inf], np.nan)\n",
    "    features_df = features_df.dropna()\n",
    "    features_df = features_df[features_df != 0.0].shift(1).dropna()\n",
    "\n",
    "    return features_df\n",
    "\n",
    "def get_log_total_trade_vol(df):\n",
    "    log_total_traded_vol = get_log(get_total_traded_vol(df))\n",
    "    log_total_traded_vol.name = \"log_total_traded_vol\"\n",
    "    \n",
    "    return log_total_traded_vol \n",
    "\n",
    "def get_total_traded_vol(df):\n",
    "    total_traded_vol = df.resample('B').first()[VOLUME]\n",
    "    total_traded_vol.name = \"total_traded_vol\"\n",
    "\n",
    "    return total_traded_vol\n",
    "\n",
    "def get_log_open_close_returns(df):\n",
    "    open_close_returns = np.log(df[OPEN_PRICE]/df[CLOSE_PRICE].shift(-1)).dropna()\n",
    "    open_close_returns.name = \"log_overnight_returns\"\n",
    "\n",
    "    return open_close_returns\n",
    "\n",
    "def get_log_returns(df):\n",
    "    close = df[CLOSE_PRICE].resample('B').last()\n",
    "    log_daily_returns = np.log(close/close.shift(-1))\n",
    "    log_daily_returns.name = \"log_returns\"\n",
    "\n",
    "    return log_daily_returns\n",
    "\n",
    "def get_high_low_spread(df):\n",
    "    high_low_spread = (df[HIGH_PRICE]-df[LOW_PRICE])\n",
    "    high_low_spread.name = \"high_low_spread\"\n",
    "\n",
    "    return high_low_spread\n",
    "\n",
    "def get_log(df):\n",
    "    return np.log(df)\n",
    "\n",
    "def get_antilog_adv_median(df):\n",
    "    antilog_adv = np.exp(get_log(daily_data[VOLUME]).rolling(20, min_periods=5).median().dropna())\n",
    "    antilog_adv.name = \"antilog_adv\"\n",
    "    \n",
    "    return antilog_adv\n",
    "\n",
    "def get_money_flow_index(df):\n",
    "    typical_price = (df[CLOSE_PRICE]+df[HIGH_PRICE]+df[LOW_PRICE])/3\n",
    "    volume = df[VOLUME]\n",
    "    money_flow_index = typical_price/volume\n",
    "    money_flow_index.name = \"money_flow_index\"\n",
    "\n",
    "    return money_flow_index\n",
    "\n",
    "def get_beta_market_impact(df):\n",
    "    adv_antilog = get_antilog_adv_median(df)\n",
    "    X = df[VOLUME]/adv_antilog\n",
    "    Y = ((df[VWAP]-df[OPEN_PRICE])/df[OPEN_PRICE])*1e4\n",
    "    betas = X/Y\n",
    "    betas.name = \"betas_market_impact\"\n",
    "    \n",
    "    return betas\n",
    "\n",
    "features_list = get_features_series_list(daily_data)\n",
    "features_df_new = get_features_df(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_total_traded_vol</th>\n",
       "      <th>money_flow_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2003-06-27</td>\n",
       "      <td>14.716221</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-07-03</td>\n",
       "      <td>14.231743</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-07-04</td>\n",
       "      <td>13.325325</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-07-07</td>\n",
       "      <td>13.853255</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-07-08</td>\n",
       "      <td>14.521313</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>13.817550</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>14.139078</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>13.271175</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>13.615681</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>13.318502</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4035 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            log_total_traded_vol  money_flow_index\n",
       "date_time                                         \n",
       "2003-06-27             14.716221          0.000013\n",
       "2003-07-03             14.231743          0.000022\n",
       "2003-07-04             13.325325          0.000055\n",
       "2003-07-07             13.853255          0.000033\n",
       "2003-07-08             14.521313          0.000017\n",
       "...                          ...               ...\n",
       "2019-10-04             13.817550          0.000065\n",
       "2019-10-07             14.139078          0.000045\n",
       "2019-10-08             13.271175          0.000107\n",
       "2019-10-09             13.615681          0.000076\n",
       "2019-10-10             13.318502          0.000102\n",
       "\n",
       "[4035 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_use = [\"log_total_traded_vol\", \"money_flow_index\"]\n",
    "features_df_new[features_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test MFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mfi old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfi_old = formatted_df\n",
    "close = df_mfi_old[CLOSE_PRICE].resample('B').last()\n",
    "high = df_mfi_old[HIGH_PRICE].resample('B').max()\n",
    "low = df_mfi_old[LOW_PRICE].resample('B').min()\n",
    "typical_price = (close+high+low)/3\n",
    "volume = df_mfi_old[VOLUME].resample('B').sum()\n",
    "money_flow_index = typical_price/volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mfi_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-13e1100413c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_mfi_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCLOSE_PRICE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mfi_new' is not defined"
     ]
    }
   ],
   "source": [
    "df_mfi_new[CLOSE_PRICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2003-06-19 17:35:00    31.96\n",
       "2003-06-20 09:01:00    31.90\n",
       "2003-06-20 09:02:00    31.96\n",
       "2003-06-20 09:03:00    31.80\n",
       "2003-06-20 09:04:00    31.68\n",
       "                       ...  \n",
       "2019-10-11 17:27:00    64.80\n",
       "2019-10-11 17:28:00    64.86\n",
       "2019-10-11 17:29:00    64.83\n",
       "2019-10-11 17:30:00    64.80\n",
       "2019-10-11 17:35:00    64.78\n",
       "Name: close, Length: 1970723, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfi_old[CLOSE_PRICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2003-06-19    31.96\n",
       "2003-06-20    32.35\n",
       "2003-06-23    31.84\n",
       "2003-06-24    32.41\n",
       "2003-06-25    32.30\n",
       "              ...  \n",
       "2019-10-07    62.68\n",
       "2019-10-08    61.86\n",
       "2019-10-09    62.35\n",
       "2019-10-10    63.23\n",
       "2019-10-11    64.78\n",
       "Freq: B, Name: close, Length: 4257, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2003-06-20    32.440000\n",
       "2003-06-23    31.890000\n",
       "2003-06-24    32.296667\n",
       "2003-06-25    32.480000\n",
       "2003-06-26    32.873333\n",
       "                ...    \n",
       "2019-10-07    62.190000\n",
       "2019-10-08    62.080000\n",
       "2019-10-09    62.073333\n",
       "2019-10-10    63.093333\n",
       "2019-10-11    64.296667\n",
       "Length: 4143, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typical_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mfi new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfi_new = daily_data\n",
    "typical_price = (df_mfi_new[CLOSE_PRICE]+df_mfi_new[HIGH_PRICE]+df_mfi_new[LOW_PRICE])/3\n",
    "volume = df_mfi_new[VOLUME]\n",
    "money_flow_index = typical_price/volume\n",
    "money_flow_index.name = \"money_flow_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2003-06-20    32.75\n",
       "2003-06-23    31.85\n",
       "2003-06-24    32.39\n",
       "2003-06-25    32.49\n",
       "2003-06-26    33.28\n",
       "              ...  \n",
       "2019-10-07    62.54\n",
       "2019-10-08    61.89\n",
       "2019-10-09    62.14\n",
       "2019-10-10    63.44\n",
       "2019-10-11    64.80\n",
       "Name: close, Length: 4143, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfi_new[CLOSE_PRICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2003-06-20    32.440000\n",
       "2003-06-23    31.890000\n",
       "2003-06-24    32.296667\n",
       "2003-06-25    32.480000\n",
       "2003-06-26    32.873333\n",
       "                ...    \n",
       "2019-10-07    62.190000\n",
       "2019-10-08    62.080000\n",
       "2019-10-09    62.073333\n",
       "2019-10-10    63.093333\n",
       "2019-10-11    64.296667\n",
       "Length: 4143, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typical_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(df, size_in_years):\n",
    "    training_data = df[df.index[0]:df.index[-1] - relativedelta(years=size_in_years, hours=-9, minutes = -5)]\n",
    "    test_data = df[df.index[-1] - relativedelta(years=size_in_years, hours=-9):]\n",
    "\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=3, covariance_type='full', max_iter=1000, n_init=100, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=3, covariance_type='full', n_iter=1000, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_train, data_to_test = split_train_test_data(data_to_predict, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, full_data, train_data, list_of_features):\n",
    "    X = train_data.values\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    if len(list_of_features) > 2:\n",
    "        pca = PCA(n_components=.95)\n",
    "        pca.fit(X_scaled)\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        fitted_model = model.fit(X_pca)\n",
    "        X_full = full_data.values\n",
    "        X_full_scaled = scaler.transform(X_full)\n",
    "        X_full_pca = pca.transform(X_full_scaled)\n",
    "        prediction = fitted_model.predict(X_full_pca)\n",
    "    else:\n",
    "        fitted_model = model.fit(X_scaled)\n",
    "        X_full = full_data.values\n",
    "        X_full_scaled = scaler.transform(X_full)\n",
    "        prediction = fitted_model.predict(X_full_scaled)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "model_old = hmm\n",
    "X = data_to_train.values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "pca = PCA(n_components=.95)\n",
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "fitted_model = model_old.fit(X_pca)\n",
    "X_full = data_to_predict.values\n",
    "X_full_scaled = scaler.transform(X_full)\n",
    "X_full_pca = pca.transform(X_full_scaled)\n",
    "prediction_old = fitted_model.predict(X_full_pca)\n",
    "regime_old = pd.Series(data = prediction_old, index = data_to_predict.index).rename(\"regime\")\n",
    "regime_old = regime_old.resample(\"5T\").asfreq().fillna(method=\"ffill\")\n",
    "\n",
    "new_df = pd.merge(algo_df, regime_old, left_index=True, right_index=True)\n",
    "new_df = new_df.astype({\"regime\":\"int32\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new, test_new = split_train_test_data(features_df_new[features_to_use], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = gmm\n",
    "X = train_new.values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "pca = PCA(n_components=.95)\n",
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "fitted_model_new = new_model.fit(X_pca)\n",
    "X_full = features_df_new[features_to_use].values\n",
    "X_full_scaled = scaler.transform(X_full)\n",
    "X_full_pca = pca.transform(X_full_scaled)\n",
    "prediction_new = fitted_model_new.predict(X_full_pca)\n",
    "\n",
    "regime = pd.Series(data = prediction_new, index = features_df_new[features_to_use].index).rename(\"regime\")\n",
    "\n",
    "regime_intraday = pd.merge(intraday_data, regime.resample(\"5T\").asfreq().fillna(method=\"ffill\"), left_index=True, right_index=True)\n",
    "regime_intraday = regime_intraday.astype({\"regime\":\"int32\"})\n",
    "\n",
    "regime_daily = pd.merge(daily_data, regime, left_index=True, right_index=True)\n",
    "regime_daily = regime_daily.astype({\"regime\":\"int32\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Dinamico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_old, test_old = split_train_test_data(new_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeekdaysDataDict(df):\n",
    "    weekdaysDataDict = {}\n",
    "    weekdaysDataDict[0] = df[df.index.weekday == 0]\n",
    "    weekdaysDataDict[1] = df[df.index.weekday == 1]\n",
    "    weekdaysDataDict[2] = df[df.index.weekday == 2]\n",
    "    weekdaysDataDict[3] = df[df.index.weekday == 3]\n",
    "    weekdaysDataDict[4] = df[df.index.weekday == 4]\n",
    "    weekdaysDataDict['else'] = df\n",
    "\n",
    "    return weekdaysDataDict\n",
    "\n",
    "def getStaticVolPredictorByWeekday(data, weekdaysDataDict):\n",
    "    staticVolPredictor = {}\n",
    "    staticVolPredictor[0] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(0))\n",
    "    staticVolPredictor[1] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(1))\n",
    "    staticVolPredictor[2] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(2))\n",
    "    staticVolPredictor[3] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(3))\n",
    "    staticVolPredictor[4] = getNormalizedStaticVolPredictor(weekdaysDataDict.get(4))\n",
    "    staticVolPredictor['else'] = getNormalizedStaticVolPredictor(data)\n",
    "\n",
    "    return staticVolPredictor\n",
    "\n",
    "def getNormalizedStaticVolPredictor(df):\n",
    "    df = addDateAndTime(df)\n",
    "\n",
    "    static_volume_predictor = df.groupby(by='time')['volume'].median()\n",
    "    norm_static_volume_predictor = static_volume_predictor/sum(static_volume_predictor)\n",
    "    norm_static_volume_predictor.index = norm_static_volume_predictor.index.map(lambda x: datetime.strptime(x, '%X').time())\n",
    "\n",
    "    return norm_static_volume_predictor\n",
    "\n",
    "def getADVMedian(df):\n",
    "    return df['volume'].groupby(df.index.date).sum().median()\n",
    "\n",
    "def getADVMedianByWeekday(data, weekdaysDataDict):\n",
    "    advMedian = {}\n",
    "    advMedian[0] = getADVMedian(weekdaysDataDict.get(0))\n",
    "    advMedian[1] = getADVMedian(weekdaysDataDict.get(1))\n",
    "    advMedian[2] = getADVMedian(weekdaysDataDict.get(2))\n",
    "    advMedian[3] = getADVMedian(weekdaysDataDict.get(3))\n",
    "    advMedian[4] = getADVMedian(weekdaysDataDict.get(4))\n",
    "    advMedian['else'] = getADVMedian(data)\n",
    "\n",
    "    return advMedian\n",
    "\n",
    "regimes_old = np.unique(new_df['regime'])\n",
    "regime_daily_vwap = {}\n",
    "regime_weekdaysDataDict = {}\n",
    "regime_staticVolPredictor = {}\n",
    "regime_advMedian = {}\n",
    "# daily_vwap = getDailyVWAP(test_data)\n",
    "daily_vwap_old = test_old['volume*price'].groupby(test_old.index.date).sum()/test_old['volume'].groupby(test_old.index.date).sum()\n",
    "for regime in regimes_old:\n",
    "    this_regime_test_data_old = test_old[test_old['regime']==regime]\n",
    "    this_regime_train_data_old = train_old[train_old['regime']==regime]\n",
    "#         regime_daily_vwap[regime] = getDailyVWAP(test_data[test_data['regime'] == regime])\n",
    "    regime_daily_vwap = this_regime_test_data_old['volume*price'].groupby(this_regime_test_data_old.index.date).sum()/this_regime_test_data_old['volume'].groupby(this_regime_test_data_old.index.date).sum()\n",
    "#     regime_weekdaysDataDict[regime] = getWeekdaysDataDict(training_data[training_data['regime'] == regime])\n",
    "    regime_weekdaysDataDict[regime] = getWeekdaysDataDict(this_regime_train_data_old)\n",
    "    regime_staticVolPredictor[regime] = getStaticVolPredictorByWeekday(this_regime_train_data_old, regime_weekdaysDataDict[regime])\n",
    "    regime_advMedian[regime] = getADVMedianByWeekday(this_regime_train_data_old, regime_weekdaysDataDict[regime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BacktestAlgoDynamicByRegime\n",
    "\n",
    "def dataToMultiIndex(data):\n",
    "    multi_data = data.copy()\n",
    "    multi_data.index = pd.MultiIndex.from_arrays([multi_data.index.date, multi_data.index.time], names=['Date','Time'])\n",
    "\n",
    "    return multi_data\n",
    "\n",
    "def getReversedCumVol(multi_data, data):\n",
    "    reversed_cumvol = []\n",
    "    for day in multi_data.index.get_level_values('Date').unique():\n",
    "        reversed_cumvol.append(multi_data.xs(day, level='Date')['volume'].cumsum().values[::-1])\n",
    "\n",
    "    reversed_cumvol = pd.Series(data = np.concatenate(reversed_cumvol), index = data.index)\n",
    "\n",
    "    return reversed_cumvol\n",
    "\n",
    "def getVolPredictorNextBin(test_data, staticVolPredictor, advMedian):\n",
    "    volume_predictor_next_interval = test_data.groupby(level=0)['volume'].shift(1)\n",
    "    volume_predictor_next_interval.fillna(int (advMedian.get('else')*staticVolPredictor.get('else').iloc[0]), inplace=True)\n",
    "\n",
    "    return volume_predictor_next_interval\n",
    "\n",
    "training_data = train_old\n",
    "test_data = test_old\n",
    "advMedian = regime_advMedian\n",
    "staticVolPredictor = regime_staticVolPredictor\n",
    "\n",
    "new_training_data = dataToMultiIndex(training_data)\n",
    "new_test_data = dataToMultiIndex(test_data)\n",
    "regime_reversedCumVol = {}\n",
    "regime_volPredictorNextBin = {}\n",
    "\n",
    "for regime in regimes_old:\n",
    "    regime_reversedCumVol[regime] = getReversedCumVol(new_training_data[new_training_data['regime']==regime], \n",
    "                                                 training_data[training_data['regime']==regime])\n",
    "    regime_volPredictorNextBin[regime] = getVolPredictorNextBin(new_test_data[new_test_data['regime']==regime], \n",
    "                                                                        staticVolPredictor.get(regime),\n",
    "                                                                        advMedian.get(regime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vwap_dynamic_execution_algo(data, reversed_cumvol, staticVolPredictor, volume_predictor_next_interval, amount_shares, order_side, start_time, end_time, day):\n",
    "    shares_per_interval = []\n",
    "    if day.weekday() == 0:\n",
    "        shares_per_interval.append(staticVolPredictor.get(0).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 0].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 0].index.time).median()\n",
    "    elif day.weekday() == 1:\n",
    "        shares_per_interval.append(staticVolPredictor.get(1).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 1].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 1].index.time).median()\n",
    "    elif day.weekday() == 2:\n",
    "        shares_per_interval.append(staticVolPredictor.get(2).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 2].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 2].index.time).median()\n",
    "    elif day.weekday() == 3:\n",
    "        shares_per_interval.append(staticVolPredictor.get(3).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 3].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 3].index.time).median()\n",
    "    elif day.weekday() == 4:\n",
    "        shares_per_interval.append(staticVolPredictor.get(4).iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol[reversed_cumvol.index.weekday == 4].groupby(reversed_cumvol[reversed_cumvol.index.weekday == 4].index.time).median()\n",
    "    else:\n",
    "        shares_per_interval.append(staticVolPredictor.get('else').iloc[0]*amount_shares)\n",
    "        volPredictor = reversed_cumvol.groupby(reversed_cumvol.index.time).median()\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        num = data['volume'].iloc[:i].sum()+volume_predictor_next_interval.xs(day, level='Date').iloc[i]\n",
    "        denom = data['volume'].iloc[:i].sum()+volPredictor[i]\n",
    "        op = amount_shares*(num/denom)\n",
    "        shares_next_interval = op - sum(shares_per_interval)\n",
    "        #     shares_next_interval = (amount_shares*((data['volume'].iloc[0:i].sum()+volume_predictor_next_interval.xs(day, level='Date').iloc[i])/(data['volume'].iloc[0:i].sum()+volPredictor[i])))-sum(shares_per_interval)\n",
    "        shares_per_interval.append(shares_next_interval)\n",
    "\n",
    "    vwap_this_exec_this_day = sum(shares_per_interval*data['vwap'])/sum(shares_per_interval)\n",
    "\n",
    "    return vwap_this_exec_this_day\n",
    "\n",
    "backtest_sell_vwap_dynamic = []\n",
    "backtest_buy_vwap_dynamic = []\n",
    "for day in new_test_data.index.get_level_values('Date').unique():\n",
    "    data = new_test_data.xs(day, level='Date')\n",
    "    regime = data['regime'].iloc[0]\n",
    "    if day.weekday() == 0:\n",
    "        amount_shares = advMedian.get(regime).get(0)*0.1\n",
    "    elif day.weekday() == 1:\n",
    "        amount_shares = advMedian.get(regime).get(1)*0.1\n",
    "    elif day.weekday() == 2:\n",
    "        amount_shares = advMedian.get(regime).get(2)*0.1\n",
    "    elif day.weekday() == 3:\n",
    "        amount_shares = advMedian.get(regime).get(3)*0.1\n",
    "    elif day.weekday() == 4:\n",
    "        amount_shares = advMedian.get(regime).get(4)*0.1\n",
    "    else:\n",
    "        amount_shares = advMedian.get(regime).get('else')*0.1\n",
    "\n",
    "    backtest_sell_vwap_dynamic.append(vwap_dynamic_execution_algo(data, \n",
    "                                                                  regime_reversedCumVol.get(regime),\n",
    "                                                                  regime_staticVolPredictor.get(regime),\n",
    "                                                                  regime_volPredictorNextBin.get(regime),\n",
    "                                                                  amount_shares, \n",
    "                                                                  'sell',\n",
    "                                                                  data.index[0],\n",
    "                                                                  data.index[-1], day))\n",
    "    backtest_buy_vwap_dynamic.append(vwap_dynamic_execution_algo(data,\n",
    "                                                                 regime_reversedCumVol.get(regime),\n",
    "                                                                 regime_staticVolPredictor.get(regime),\n",
    "                                                                 regime_volPredictorNextBin.get(regime),\n",
    "                                                                 amount_shares,\n",
    "                                                                 'buy',\n",
    "                                                                 data.index[0],\n",
    "                                                                 data.index[-1],\n",
    "                                                                 day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_vwap_comparison = pd.DataFrame(data=daily_vwap_old.values.tolist(), index=daily_vwap_old.index, columns=['market_vwap'])\n",
    "static_vwap_comparison['backtest_buy_vwap'] = backtest_buy_vwap_dynamic\n",
    "static_vwap_comparison['backtest_sell_vwap'] = backtest_sell_vwap_dynamic\n",
    "\n",
    "static_vwap_comparison['diff_vwap_bps_buy'] = 1000*(static_vwap_comparison['backtest_buy_vwap']-static_vwap_comparison['market_vwap'])/static_vwap_comparison['market_vwap']\n",
    "static_vwap_comparison['diff_vwap_bps_sell'] = -1000*(static_vwap_comparison['backtest_sell_vwap']-static_vwap_comparison['market_vwap'])/static_vwap_comparison['market_vwap']\n",
    "\n",
    "mean_bps_diff_buys = static_vwap_comparison['diff_vwap_bps_buy'].mean()\n",
    "sd_bps_diff_buys = static_vwap_comparison['diff_vwap_bps_buy'].std()\n",
    "mean_bps_diff_sells = static_vwap_comparison['diff_vwap_bps_sell'].mean()\n",
    "sd_bps_diff_sells = static_vwap_comparison['diff_vwap_bps_sell'].std()\n",
    "\n",
    "percentiles_diff_vwap_sells = {'1': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.01),\n",
    "                           '5': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.05),\n",
    "                           '95': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.95),\n",
    "                           '99': static_vwap_comparison['diff_vwap_bps_sell'].quantile(0.99)}\n",
    "percentiles_diff_vwap_buys = {'1': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.01),\n",
    "                           '5': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.05),\n",
    "                           '95': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.95),\n",
    "                           '99': static_vwap_comparison['diff_vwap_bps_buy'].quantile(0.99)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker=\"BMW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of the algorithm using static predictor with segmented data on BMW is\n",
      "Mean: ±0.049160\n",
      "Standard Dev: ±1.117328\n"
     ]
    }
   ],
   "source": [
    "print(\"The performance of the algorithm using static predictor with segmented data on \" + ticker + \" is\")\n",
    "print(\"Mean: ±%f\\nStandard Dev: ±%f\" % (np.abs(mean_bps_diff_buys), sd_bps_diff_buys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "intraday_train, intraday_test = split_train_test_data(regime_intraday, 2)\n",
    "daily_train, daily_test = split_train_test_data(regime_daily, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_median(df):\n",
    "    return df['volume'].groupby(df.index.date).sum().median()\n",
    "\n",
    "def get_weekdays_data_dict(df):\n",
    "    weekdays_data_dict = {}\n",
    "    weekdays_data_dict[0] = df[df.index.weekday == 0]\n",
    "    weekdays_data_dict[1] = df[df.index.weekday == 1]\n",
    "    weekdays_data_dict[2] = df[df.index.weekday == 2]\n",
    "    weekdays_data_dict[3] = df[df.index.weekday == 3]\n",
    "    weekdays_data_dict[4] = df[df.index.weekday == 4]\n",
    "    weekdays_data_dict['else'] = df\n",
    "\n",
    "    return weekdays_data_dict\n",
    "\n",
    "def get_static_vol_predictor_by_weekday(data, weekdays_data_dict):\n",
    "    static_vol_predictor = {}\n",
    "    static_vol_predictor[0] = get_norm_static_vol_predictor(weekdays_data_dict.get(0))\n",
    "    static_vol_predictor[1] = get_norm_static_vol_predictor(weekdays_data_dict.get(1))\n",
    "    static_vol_predictor[2] = get_norm_static_vol_predictor(weekdays_data_dict.get(2))\n",
    "    static_vol_predictor[3] = get_norm_static_vol_predictor(weekdays_data_dict.get(3))\n",
    "    static_vol_predictor[4] = get_norm_static_vol_predictor(weekdays_data_dict.get(4))\n",
    "    static_vol_predictor['else'] = get_norm_static_vol_predictor(data)\n",
    "\n",
    "    return static_vol_predictor\n",
    "\n",
    "def get_adv_median_by_weekday(data, weekdays_data_dict):\n",
    "    adv_median = {}\n",
    "    adv_median[0] = get_adv_median(weekdays_data_dict.get(0))\n",
    "    adv_median[1] = get_adv_median(weekdays_data_dict.get(1))\n",
    "    adv_median[2] = get_adv_median(weekdays_data_dict.get(2))\n",
    "    adv_median[3] = get_adv_median(weekdays_data_dict.get(3))\n",
    "    adv_median[4] = get_adv_median(weekdays_data_dict.get(4))\n",
    "    adv_median['else'] = get_adv_median(data)\n",
    "\n",
    "    return adv_median\n",
    "  \n",
    "def get_data_by_weekday(df, weekday):\n",
    "    df_weekday = df[df.index.weekday == weekday]\n",
    "\n",
    "    return df_weekday\n",
    "\n",
    "def add_datetime(df):\n",
    "    returned_df = df.copy()\n",
    "    returned_df['date'] = pd.to_datetime(returned_df.index.date)\n",
    "    returned_df['time'] = pd.to_datetime(returned_df.index, format = \"%m-%d-%Y %H:%M:%S\")\n",
    "    returned_df['time'] = returned_df['time'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "\n",
    "    return returned_df\n",
    "\n",
    "def get_norm_static_vol_predictor(df):\n",
    "    static_volume_predictor = df.groupby(by=df.index.time)[VOLUME].median()\n",
    "    norm_static_volume_predictor = static_volume_predictor/sum(static_volume_predictor)\n",
    "\n",
    "    return norm_static_volume_predictor\n",
    "\n",
    "vwap_and_regime = daily_test[[VWAP, \"regime\"]]\n",
    "regime_daily_vwap = {}\n",
    "regime_weekdays_data_dict = {}\n",
    "regime_static_vol_predictor = {}\n",
    "regime_adv_median = {}\n",
    "daily_vwap_new = vwap_and_regime[VWAP]\n",
    "for regime in regimes:\n",
    "    regime_daily_vwap[regime] = vwap_and_regime[vwap_and_regime['regime'] == regime][VWAP]\n",
    "    regime_weekdays_data_dict[regime] = get_weekdays_data_dict(intraday_train[intraday_train['regime'] == regime])\n",
    "    regime_static_vol_predictor[regime] = get_static_vol_predictor_by_weekday(intraday_train[intraday_train['regime'] == regime],\n",
    "                                                                              regime_weekdays_data_dict[regime])\n",
    "    regime_adv_median[regime] = get_adv_median_by_weekday(intraday_train[intraday_train['regime'] == regime], \n",
    "                                                              regime_weekdays_data_dict[regime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
